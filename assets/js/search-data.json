{
  
    
        "post0": {
            "title": "Learning to resize images for CV tasks",
            "content": "Resources . Paper | https://www.kaggle.com/ipythonx/learning-to-resize-images-for-vision-transformer | Generally, for CV tasks, we use resize that uses bilinear and bicubic interpolation to resize images. Resize is necessary for the model to be efficient but, at times, come at a cost of model accuracy. . In this paper, a new technique was introduced for resizing images for CV tasks. One in which resize takes place by a learning mechanism instead of hard-coding the resize. . . Source: Learning to Resize Images for Computer Vision Tasks . . Source: Learning to Resize Images for Computer Vision Tasks . As we can see the proposed method reduces the error-rate for different architecture in classification tasks. . . Source: Learning to Resize Images for Computer Vision Tasks . The above image captures the model architecture as well as the process. . In this blog, we will explore this technique using fastai and timm&#39;s Swin Transformed model . The Dataset . We will use the imagenette dataset by fastai . lbl_dict = dict( n01440764=&#39;tench&#39;, n02102040=&#39;English springer&#39;, n02979186=&#39;cassette player&#39;, n03000684=&#39;chain saw&#39;, n03028079=&#39;church&#39;, n03394916=&#39;French horn&#39;, n03417042=&#39;garbage truck&#39;, n03425413=&#39;gas pump&#39;, n03445777=&#39;golf ball&#39;, n03888257=&#39;parachute&#39; ) def label_func(fname): return lbl_dict[parent_label(fname)] . dblock = DataBlock(blocks = (ImageBlock, CategoryBlock), get_items = get_image_files, get_y = label_func, splitter = GrandparentSplitter(valid_name=&#39;val&#39;), item_tfms = Resize(224), batch_tfms=Normalize.from_stats(*imagenet_stats)) dls = dblock.dataloaders(path, bs=8) . dls.show_batch() . Training with normal resizer . model = create_model(&#39;swin_large_patch4_window7_224&#39;, pretrained=True, num_classes=dls.c) . learn = Learner(dls, model, cbs=[GradientAccumulation(12), GradientClip()], metrics=[accuracy, error_rate]) . learn.fit_one_cycle(5) . epoch train_loss valid_loss accuracy error_rate time . 0 | 0.829841 | 0.823315 | 0.780382 | 0.219618 | 29:55 | . 1 | 0.657223 | 0.741026 | 0.798217 | 0.201783 | 29:56 | . 2 | 0.416582 | 0.399281 | 0.883567 | 0.116433 | 29:55 | . 3 | 0.249072 | 0.257628 | 0.924841 | 0.075159 | 30:06 | . 4 | 0.061879 | 0.187841 | 0.951592 | 0.048408 | 30:06 | . Training with learned resizer . dblock = DataBlock(blocks = (ImageBlock, CategoryBlock), get_items = get_image_files, get_y = label_func, splitter = GrandparentSplitter(valid_name=&#39;val&#39;), item_tfms = Resize(512), batch_tfms=Normalize.from_stats(*imagenet_stats)) dls = dblock.dataloaders(path, bs=4) . class ResBlock(nn.Module): def __init__(self,num_channels=16): super(ResBlock,self).__init__() self.conv1 = nn.Conv2d(num_channels,num_channels,kernel_size=3,stride=1,padding=1) self.bn1 = nn.BatchNorm2d(num_channels) self.leakyrelu = nn.LeakyReLU(negative_slope=0.2,inplace=True) self.conv2 = nn.Conv2d(num_channels,num_channels,kernel_size=3,stride=1,padding=1) self.bn2 = nn.BatchNorm2d(num_channels) def forward(self,x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.leakyrelu(out) out = self.conv2(out) out = self.bn2(out) out += residual return out def make_block(r,n): residual = [] for i in range(r): block = ResBlock(num_channels=n) residual.append(block) return nn.Sequential(*residual) class ResizingNetwork(nn.Module): def __init__(self, img_size, in_chans = 3, r=1, n=16): super(ResizingNetwork, self).__init__() self.img_size = img_size self.conv1 = nn.Conv2d(in_channels=in_chans, out_channels=n, kernel_size=7,stride=1,padding=3) self.leakyrelu1 = nn.LeakyReLU(negative_slope=0.2,inplace=True) self.conv2 = nn.Conv2d(n,n,kernel_size=1,stride=1) self.leakyrelu2 = nn.LeakyReLU(negative_slope=0.2,inplace=True) self.bn1 = nn.BatchNorm2d(n) self.resblock = make_block(r,n) self.conv3 = nn.Conv2d(n,n,kernel_size=3,stride=1,padding=1) self.bn2 = nn.BatchNorm2d(n) self.conv4 = nn.Conv2d(n,out_channels=in_chans,kernel_size=7,stride=1,padding=3) def forward(self, x): residual = F.interpolate(x, size=(self.img_size, self.img_size), mode=&#39;bilinear&#39;, align_corners=False) out = self.conv1(x) out = self.leakyrelu1(out) out = self.conv2(out) out = self.leakyrelu2(out) out = self.bn1(out) out_residual = F.interpolate(out, size=(self.img_size, self.img_size), mode=&#39;bilinear&#39;, align_corners=False) out = self.resblock(out_residual) out = self.conv3(out) out = self.bn2(out) out += out_residual out = self.conv4(out) out += residual return out . class LRSwinModel(Module): def __init__(self, img_size=224): self.resizenet = ResizingNetwork(img_size) self.swin = create_model(&#39;swin_large_patch4_window7_224&#39;, pretrained=True, num_classes=dls.c) def forward(self, x): x = self.resizenet(x) x = self.swin(x) return x . model = LRSwinModel() . Downloading: &#34;https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window7_224_22kto1k.pth&#34; to /root/.cache/torch/hub/checkpoints/swin_large_patch4_window7_224_22kto1k.pth . learn = Learner(dls, model, cbs=[GradientAccumulation(24), GradientClip()], metrics=[accuracy, error_rate]) . learn.fit_one_cycle(5) . . 20.00% [1/5 38:02&lt;2:32:08] epoch train_loss valid_loss accuracy error_rate time . 0 | 0.675374 | 0.573788 | 0.824713 | 0.175287 | 38:02 | . . 24.33% [576/2367 08:01&lt;24:58 0.6032] &lt;/div&gt; &lt;/div&gt; epoch train_loss valid_loss accuracy error_rate time . 0 | 0.675374 | 0.573788 | 0.824713 | 0.175287 | 38:02 | . 1 | 0.655572 | 0.450714 | 0.867261 | 0.132739 | 38:01 | . 2 | 0.330661 | 0.315596 | 0.907261 | 0.092739 | 38:02 | . 3 | 0.115059 | 0.159794 | 0.953885 | 0.046115 | 37:58 | . 4 | 0.030658 | 0.142762 | 0.961274 | 0.038726 | 38:03 | . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; As we can see from the above example, using learned resizer results in better accuracy/error rate and helps to reach this at a faster rate. . &lt;/div&gt; .",
            "url": "https://moarshy.github.io/blogs/computer%20vision/vision%20transformer/fastai/classification/2021/11/13/_10_30_LearnedResizer.html",
            "relUrl": "/computer%20vision/vision%20transformer/fastai/classification/2021/11/13/_10_30_LearnedResizer.html",
            "date": " • Nov 13, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Medical Specialty Classification Using Patient Query",
            "content": "The Problem Statement . . Recently, one of my friend came down with a pain around his wrist. Because I work at a hospital, he asked me to pick a medical specialist for him to consult. Since I am a good friend, I suggested for him to visit the best hand surgeon in town. . Being a good friend, I followed up on his consult. To my surprise, he said he had to see an urologist because it could be a kidney stone. . WHAT??! Kidney stones. You must be kidding. . Apparently, that is a possibility. The wrist pain could be a result of gout which in turn could be a result of kidney stones. For more info on joint pain, gout and kidney stones see this( link text) . That is when the idea for this blog popped up. . In this blog we ask the question, Can we build an AI chatbox that takes in a patient&#39;s query and outputs an appropriate specialty the patient should see? . Such AI assistants could come in handy to some healthcare providers to guide patients to the right specialty. . It can be used by telephone operators (who might not have aqequate medical knowledge to answer such questions) at those hospitals to better serve the patients. | It can also integrated with hospital&#39;s telemedicine app to guide patients. | Now that we have defined our problem statement. Let&#39;s spell out the plan to achieve this goal. . For this we will loosely follow this paper as our guide. The paper uses NLP to tackle a similar problem. . Briefly, the following is our plan . building the dataset . we will extract patient queries from online medical forums | the queries are organised under different topics such as diabetes, thyroid issues | we manually map the topics to specialty | clean the queries | . | training using fastai&#39;s ULMFit . build a language model using the dataset we have prepared | build a text classifier using the dataset and the encoader we duild during the language model training | . | inference and understanding what we have built . | Preparing the dataset . This is the raw dataset following scraping the data from medical forums. . df_raw.head(5) . text topic . 0 Gut issues n nI realized I was eating to make my stomach feel better. I would eat normal several days then I could not get enough to eat felt like I was starving. So I decided to treat myself and do a 2 week course of Prilosec. I did this for several years every 6 months seemed to put stomach back to normal. I was trying to save on Dr. bills as I have other issues. So in May I had a vomiting spell of burning acid and abdominal pain did not go to Doctor. I came down with urinary infection right after showing blood in urine. I went on antibiotics. They sent me for tests to see if kidney... | Abdominal Disorders | . 1 Has anyone experienced gastritis as a side effect of an SSRI (antidepressant)? n nI had been on Escitalopram for 5 years when I developed intermittent nausea. After switching to Sertraline, I developed a very sore stomach and the nausea became constant and severe. A gastroscopy diagnosed stomach-wide, non-erosive gastritis (H.Pylori-negative). This has not improved in 6 weeks of taking a PPI and an H2 blocker but I have been continuing to take Sertraline. nI cannot find any articles about an increased risk of Gastritis from Sertraline (although there is some link with gastric bleeding), b... | Abdominal Disorders | . 2 Severe stomach pain and flare up every 2-3 weeks n nsince April 21 I have been having these so called flare ups (doctors name for them) I get severe abdominal pain where I can&#39;t move, vomiting, diarrhea, cold sweats, shakes, rapid heart beat, confusion and dizzyness, I pass out nearly every time, I ring an ambulance straight away but its been months and my doctors don&#39;t have a clue what is causing it as we&#39;ve found no triggers, I&#39;ve been on a strict diet, gluten free, no alcohol, no dairy no coffee and no spicy food. Its really disheartening not knowing what it is, is anyone else having t... | Abdominal Disorders | . 3 Plzz can anyone tell colonscopy n nhello can any one tell what i have from 2020 my stomach is not well some day i get loose type stools other day its normal i did mt colonscopy it went till ileo ceacal valve it was normal doctor said it is ibsbut still i have symptom can anyone tell me ? n0 likes, 0 replies n n n n n n n nReport / Delete n n n n n n n n n n | Abdominal Disorders | . 4 Effects of late night eating n nI don&#39;t think that eating late at night when I was young was due to an eating disorder, I think it was something I did due to a lack of understanding or knowledge of the dangers. nI&#39;m currently trying to find a diagnosis for serious health issues I have which I believe were caused by this. But, I can&#39;t seem to find any scientific answers as to what the dangers of late night eating really are. nI&#39;m 37 now, and the first symptoms I noticed that were a result of my eating habits were when I was 18. These symptoms were reflux ones, but not common ones such as h... | Abdominal Disorders | . There are about 1368 unique topics. Let&#39;s take a look at some of them. . df_raw[&#39;topic&#39;].unique()[random.choices(range(1368), k=50)] . array([&#39;Colposcopy&#39;, &#34;Sulfasalazine for Crohn&#39;s Disease&#34;, &#39;Thromboembolism&#39;, &#39;Disc Prolapse&#39;, &#34;Marfan&#39;s Syndrome&#34;, &#39;Transposition Of Great Arteries&#39;, &#39;Gynaecomastia&#39;, &#34;Fallot&#39;s Tetralogy&#34;, &#39;Portal Hypertension&#39;, &#39;Septic Arthritis&#39;, &#39;Vestibular Neuritis&#39;, &#39;Dengue Fever &#39;, &#39;Erythema&#39;, &#39;Angiotensin II Receptor Blockers&#39;, &#39;Upper Gastrointestinal Endoscopy&#39;, &#39;Sildenafil&#39;, &#39;THR&#39;, &#39;Extrinsic Allergic Alveolitis &#39;, &#39;Appendicitis&#39;, &#39;Gilberts Syndrome&#39;, &#34;Tourette&#39;s Syndrome&#34;, &#39;E coli &#39;, &#39;Varicose Vein&#39;, &#39;TKR - Total Knee Replacement&#39;, &#39;Bed Sores&#39;, &#39;Irbesartan&#39;, &#39;Allergic Rhinitis (Hay Fever)&#39;, &#39;Metabolic Disease&#39;, &#39;Fosamax&#39;, &#39;Incontinence - Urine&#39;, &#39;Acne&#39;, &#39;Colofac&#39;, &#39;DEXA Scan&#39;, &#39;Amisulpride&#39;, &#34;Perthes&#39; Disease&#34;, &#39;Pyoderma Gangrenosum&#39;, &#39;Etodolac&#39;, &#39;Oxytetracycline&#39;, &#39;Gastroenteritis&#39;, &#39;Hydatidiform Mole&#39;, &#39;Polycythaemia Rubra Vera&#39;, &#39;Orthostatic Hypotension&#39;, &#34;Fanconi&#39;s Anaemia&#34;, &#39;Osteomalacia&#39;, &#39;Backache&#39;, &#39;Abscess - Dental&#39;, &#39;Indigestion&#39;, &#39;Hair Loss and Disorders&#39;, &#39;Sciatica&#39;, &#39;Chorea&#39;], dtype=object) . As we can note some of the topics are name of medicines. In the subsequent process, I have decided to remove them. . df_processed.head(5) . text topic specialty seq_length . 0 Gut issues I realized I was eating to make my stomach feel better. I would eat normal several days then I could not get enough to eat felt like I was starving. So I decided to treat myself and do a 2 week course of Prilosec. I did this for several years every 6 months seemed to put stomach back to normal. I was trying to save on Dr. bills as I have other issues. So in May I had a vomiting spell of burning acid and abdominal pain did not go to Doctor. I came down with urinary infection right after showing blood in urine. I went on antibiotics. They sent me for tests to see if kidney sto... | Abdominal Disorders | gastroenterologist | 425 | . 1 Has anyone experienced gastritis as a side effect of an SSRI (antidepressant)? I had been on Escitalopram for 5 years when I developed intermittent nausea. After switching to Sertraline, I developed a very sore stomach and the nausea became constant and severe. A gastroscopy diagnosed stomach-wide, non-erosive gastritis (H.Pylori-negative). This has not improved in 6 weeks of taking a PPI and an H2 blocker but I have been continuing to take Sertraline.I cannot find any articles about an increased risk of Gastritis from Sertraline (although there is some link with gastric bleeding), but it ... | Abdominal Disorders | gastroenterologist | 124 | . 2 Severe stomach pain and flare up every 2-3 weeks since April 21 I have been having these so called flare ups (doctors name for them) I get severe abdominal pain where I can&#39;t move, vomiting, diarrhea, cold sweats, shakes, rapid heart beat, confusion and dizzyness, I pass out nearly every time, I ring an ambulance straight away but its been months and my doctors don&#39;t have a clue what is causing it as we&#39;ve found no triggers, I&#39;ve been on a strict diet, gluten free, no alcohol, no dairy no coffee and no spicy food. Its really disheartening not knowing what it is, is anyone else having the s... | Abdominal Disorders | gastroenterologist | 110 | . 3 Plzz can anyone tell colonscopy hello can any one tell what i have from 2020 my stomach is not well some day i get loose type stools other day its normal i did mt colonscopy it went till ileo ceacal valve it was normal doctor said it is ibsbut still i have symptom can anyone tell me ? | Abdominal Disorders | gastroenterologist | 58 | . 4 Effects of late night eating I don&#39;t think that eating late at night when I was young was due to an eating disorder, I think it was something I did due to a lack of understanding or knowledge of the dangers.I&#39;m currently trying to find a diagnosis for serious health issues I have which I believe were caused by this. But, I can&#39;t seem to find any scientific answers as to what the dangers of late night eating really are.I&#39;m 37 now, and the first symptoms I noticed that were a result of my eating habits were when I was 18. These symptoms were reflux ones, but not common ones such as heartburn... | Abdominal Disorders | gastroenterologist | 503 | . I mapped the topics to specialty to the best of knowledge. Let&#39;s take a look at some of these. . map = df_processed[[&#39;topic&#39;, &#39;specialty&#39;]].drop_duplicates(&#39;topic&#39;).set_index(&#39;topic&#39;) . . map.head(5) . specialty . topic . Abdominal Disorders gastroenterologist | . Abscess - Dental dentist | . Abscess - Non-dental general_surgeon | . Abuse psychiatrist | . Accidents and Injuries orthopedic_surgeon | . map[&#39;specialty&#39;].unique() . array([&#39;gastroenterologist&#39;, &#39;dentist&#39;, &#39;general_surgeon&#39;, &#39;psychiatrist&#39;, &#39;orthopedic_surgeon&#39;, &#39;dermatologist&#39;, &#39;neurosurgeon&#39;, &#39;endocrinologist&#39;, &#39;infection_disease&#39;, &#39;pulmonologist&#39;, &#39;neurologist&#39;, &#39;allergist&#39;, &#39;ophthalmologist&#39;, &#39;o&amp;g&#39;, &#39;oncologist&#39;, &#39;hematologist&#39;, &#39;cardiologist&#39;, &#39;rheumatologist&#39;, &#39;cardiacthoracic_surgeon&#39;, &#39;urogyn&#39;, &#39;urologist&#39;, &#39;paediatrician&#39;, &#39;otolaryngologist&#39;, &#39;nephrologist&#39;, &#39;breast_surgeon&#39;, &#39;plastic_surgeon&#39;, &#39;internal_medicine&#39;, &#39;vascular_surgeon&#39;], dtype=object) . Apart from the mapping, some basic preprocessing was also done. . removing white spaces | removing unnecessary words | Next, to training those language models. . Training using ULMFit . Language model training . dls_lm = TextDataLoaders.from_df(df_processed, is_lm=True, valid_pct=0.1) . learn = language_model_learner(dls_lm, AWD_LSTM, metrics=[accuracy, Perplexity()], wd=0.1).to_fp16() . We have defined the language model dataloader and learner as above. . Let&#39;s take a look at some of the vocab. As expected, fastai set up additional tokens such as xxunk which is used when there is an unknown word that is not part of the vocab set, xxbos to indicate beginning of sentence. . dls_lm.vocab[:30] . [&#39;xxunk&#39;, &#39;xxpad&#39;, &#39;xxbos&#39;, &#39;xxeos&#39;, &#39;xxfld&#39;, &#39;xxrep&#39;, &#39;xxwrep&#39;, &#39;xxup&#39;, &#39;xxmaj&#39;, &#39;i&#39;, &#39;.&#39;, &#39;and&#39;, &#39;,&#39;, &#39;the&#39;, &#39;to&#39;, &#39;a&#39;, &#39;my&#39;, &#39;it&#39;, &#39;of&#39;, &#39;have&#39;, &#39;in&#39;, &#39;is&#39;, &#39;for&#39;, &#39;was&#39;, &#39;that&#39;, &#39;this&#39;, &#39;but&#39;, &#39;on&#39;, &#39;with&#39;, &#39;had&#39;] . That is a sufficient number of words in the vocab. . The training for the language model is defined below. . learn.fit_one_cycle(1, 1e-2) learn.unfreeze() learn.fit_one_cycle(10, 1e-3) . Training the classifier . For classification, we first load the vocab that we built from the language model training. . vocab = load_pickle(&#39;models/vocabv2.pkl&#39;) . Then, define our classification dataloader. . dls_clas = TextDataLoaders.from_df(df_processed, text_col=&#39;text&#39;, label_col=&#39;specialty&#39;, text_vocab=vocab, valid_pct=0.1, seq_len=100, bs=64, is_lm=False, y_block=CategoryBlock()) . Let&#39;s take a look at some sample from the dls . dls_clas.show_batch() . text category . 0 xxbos pacs and pvcs … what worked for me . hello , people &#39;s research and sharing is great on these sites . xxmaj as a matter of fact , i can relate to everyone &#39;s research because we all do research . xxmaj we do it because noone has an answer . xxmaj well , i found the solution for me . xxmaj the cure , not just masking symptoms . xxmaj and , we &#39;re talking about a guy who had pacs and pvc &#39;s so bad , that xxmaj i &#39;d literally get up and drive myself to the hospital xxmaj emergency xxmaj room parking lot , and sleep in my car there because i felt secure . xxmaj now , that &#39;s after admitting myself to the hospital , so many times with the same outcome … pac &#39;s and xxup pvc &#39;s , with the | cardiologist | . 1 xxbos xxmaj could i possibly have xxmaj asperger syndrome ? i do n&#39;t really know where to start , but i guess i should start from my childhood . i have always been the elephant in the room who nearly never speaks and avoids other people . xxmaj i &#39;ve noticed i feel better and in fact , that &#39;s the only time when i talk and it &#39;s in very small groups of up to 2 people who i feel are not xxunk but i talk most with just one other person who i feel safer with , but still with restriction and no one really knows my actual self , i would say . xxmaj tbh , even i do n&#39;t . i do n&#39;t know who i am and if i am just a xxunk person who xxunk in front of that one person to be more | psychiatrist | . 2 xxbos xxup how i xxup beat xxup molluscum xxup contagiosum xxup in 1 xxup week xxup for xxup less xxup than $ 10 . xxmaj wanted to post this to help anyone else struggling with this awful infection : i had about 30 - 40 sores in my genital area and was able to achieve clear skin in 1 week . xxmaj no medicine , no dermatology appointments , just some reading online to get some background information on the infection . xxmaj if you have less sores , or in a more accessible area , this method only gets easier with an even higher likelihood of success . xxmaj other forums or doctors will tell you not to pop them because if people try to do it without understanding the gravity of the situation or the need for xxunk control of what touches what , they can make it | dermatologist | . 3 xxbos xxmaj mollescum xxmaj journey at 23 xxmaj hello ! xxmaj just a lil background info before i go into detail . xxmaj i &#39;m a 23 year old white female with mollescum on my genital area . xxmaj it took 4 months for my mollescum to even show up after i contracted it from my last sleeping partner unknowingly . 🙃 i started noticing my mollescum around early xxmaj february . xxmaj i &#39;m guessing they started to appear a week or two before but i did n&#39;t notice until they matured . ( not an often xxunk ) i initially thought they were warts because i had been tested positive for hpv last year so i made an appt with the gyno . i was due for my yearly pap smear anyways so i went in to talk about my options . xxmaj turns out my bumps were | dermatologist | . 4 xxbos xxmaj bartholin xxmaj gland xxmaj excision xxmaj experience xxmaj just wanted to hop on here and share some of my xxmaj bartholin cyst journey , because reading about the experiences from other women on here is really what helped me make the decision to finally have my gland xxunk got my first xxmaj bartholin cyst in 2014 , and it abscessed . xxmaj with a combination of three sitz baths per day in xxup acv , baking soda and xxunk xxunk tincture as well as occasional hot compresses , it burst on its own after about a week . xxmaj it returned after a couple years , but was very small and seemed to shrink on it &#39;s own . xxmaj and then , in the midst of a tough breakup , it returned again . i tried all the natural remedies , and nothing worked to make it | urogyn | . 5 xxbos xxmaj could it be xxmaj sjogren &#39;s ? xxmaj hey i &#39;m a 20 year old male and literally have no clue what is causing all my problems . i know it is rare that i could have any autoimmune disease let all alone xxmaj sjogren &#39;s as i know it is predominantly found in woman but it seems to fit to my xxunk so it started 6 months ago when i was 19 , i was absolutely fit and healthy until i came down with what i thought was a bug , i was violently sick for only a day but it was pretty bad , i ended up throwing up so much i think i got down to my stomach lining as my sick turned orange and tasted bitter . xxmaj however i got slowly better but i got pain in my testicles for a while but | rheumatologist | . 6 xxbos xxmaj coronary xxmaj artery xxmaj spasms xxmaj ok i have had this condition for years , some cardiologists agree with the diagnosis and a couple do not xxunk a long story short , last week i was out shopping , i had sudden crushing chest pain and felt really ill , had a spray , rested for 5 minutes and was able to able to continue on even though i was still feeling very unwell , the chest pain kept returning and it got to the stage where i just do what i usually do , grit my teeth and put up with it , as i was out had no other pain relief . xxmaj finished the shopping went back to my mothers to install a new telephone for her and then came home , i was then able to take my prescribed pain relief , after an | cardiologist | . 7 xxbos xxmaj chronic xxmaj lower xxmaj back xxmaj pain - xxmaj can you help ? xxmaj male , 33 years old hi , i&#39;ve had chronic low back pain for about 5 years now and it &#39;s got steadily worse . xxmaj i &#39;ve written a lot of detail here - but i &#39;m just interested in how you think i should progress in treating my lower back pain - as i &#39;ve seen a few physios now and nothings really helping and i do n&#39;t really know what the cause of my backpain is or how to get it diagnosed or treated ! ! ( at a bit of a xxunk : i&#39;m xxmaj male , 33 and i &#39;m pretty good shape ( ran london marathon last year ) . i ca nt think of any incident five years ago that caused this - there was no trauma | orthopedic_surgeon | . 8 xxbos xxmaj do i have xxmaj diabetes or xxmaj insulin xxmaj resistance or xxmaj hypoglycemia ? i have been strangely hungry a lot lately . i am a 42yr old female . i have been since i was 15 or 14 skipping meals to maintain my weight so i can eat a lot at once . xxmaj my dieting has varied from when i was a teenager and in my 20 &#39;s xxmaj i &#39;d go for 4 days each day eating less than 500 calories to binge eat for 3 days during high school and college whatever and how much food i wanted . xxmaj then in 1 xxrep 3 9 , for around 6 months i stopped , gained xxunk from xxunk to xxunk at 5&#39;0 &quot; tall . xxmaj well i did n&#39;t like the way i looked , went back to some dieting from time to | endocrinologist | . Let&#39;s define our learner to do the job. . learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.6, metrics=accuracy) . Load the encoder from the language model training. Also, lets take a look at the model we are using. . learn.model . SequentialRNN( (0): SentenceEncoder( (module): AWD_LSTM( (encoder): Embedding(24664, 400, padding_idx=1) (encoder_dp): EmbeddingDropout( (emb): Embedding(24664, 400, padding_idx=1) ) (rnns): ModuleList( (0): WeightDropout( (module): LSTM(400, 1152, batch_first=True) ) (1): WeightDropout( (module): LSTM(1152, 1152, batch_first=True) ) (2): WeightDropout( (module): LSTM(1152, 400, batch_first=True) ) ) (input_dp): RNNDropout() (hidden_dps): ModuleList( (0): RNNDropout() (1): RNNDropout() (2): RNNDropout() ) ) ) (1): PoolingLinearClassifier( (layers): Sequential( (0): LinBnDrop( (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (1): Dropout(p=0.24, inplace=False) (2): Linear(in_features=1200, out_features=50, bias=False) (3): ReLU(inplace=True) ) (1): LinBnDrop( (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (1): Dropout(p=0.1, inplace=False) (2): Linear(in_features=50, out_features=28, bias=False) ) ) ) ) . The model contain the encoder module and the classification module. Later, we will load the encoder from the language model. . learn.model[0] . SentenceEncoder( (module): AWD_LSTM( (encoder): Embedding(24664, 400, padding_idx=1) (encoder_dp): EmbeddingDropout( (emb): Embedding(24664, 400, padding_idx=1) ) (rnns): ModuleList( (0): WeightDropout( (module): LSTM(400, 1152, batch_first=True) ) (1): WeightDropout( (module): LSTM(1152, 1152, batch_first=True) ) (2): WeightDropout( (module): LSTM(1152, 400, batch_first=True) ) ) (input_dp): RNNDropout() (hidden_dps): ModuleList( (0): RNNDropout() (1): RNNDropout() (2): RNNDropout() ) ) ) . . Our training set up is as below. . learn.fit_one_cycle(3, 2e-2) learn.freeze_to(-2) learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2)) learn.freeze_to(-3) learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3)) learn.unfreeze() learn.fit_one_cycle(20, slice(1e-3/(2.6**4), 1e-3), cbs=[GradientAccumulation(16), SaveModelCallback(fname=&#39;classi_v2&#39;), EarlyStoppingCallback(comp=np.less, patience=3)]) . How is our classifier performing? . Let&#39;s try to interpret what we have achieved so far. . interp = ClassificationInterpretation.from_learner(learn) . Let&#39;s take a look at the confusion matrix . interp.plot_confusion_matrix(figsize=(15,15)) . Weighted avg f1-score of 0.87 looks decent. Overall for all classes the metrics looks fine except maybe O&amp;G, oncologist, plastic surgeon. Maybe our dataset might not contain enough data for these data. . interp.print_classification_report() . precision recall f1-score support allergist 0.93 0.91 0.92 43 breast_surgeon 0.91 0.94 0.92 31 cardiacthoracic_surgeon 0.94 0.77 0.85 39 cardiologist 0.84 0.87 0.85 115 dentist 0.95 0.77 0.85 26 dermatologist 0.87 0.92 0.90 277 endocrinologist 0.85 0.87 0.86 120 gastroenterologist 0.85 0.90 0.87 196 general_surgeon 0.89 0.84 0.87 185 hematologist 0.80 0.89 0.84 63 infection_disease 0.89 0.90 0.89 94 internal_medicine 0.89 0.81 0.85 59 nephrologist 0.78 0.82 0.80 22 neurologist 0.81 0.93 0.87 257 neurosurgeon 0.88 0.67 0.76 66 o&amp;g 0.98 0.77 0.86 83 oncologist 0.00 0.00 0.00 12 ophthalmologist 0.98 0.97 0.98 63 orthopedic_surgeon 0.88 0.91 0.90 332 otolaryngologist 0.87 0.86 0.86 122 paediatrician 0.83 0.68 0.75 59 plastic_surgeon 0.83 0.45 0.59 11 psychiatrist 0.89 0.88 0.88 189 pulmonologist 0.90 0.95 0.92 103 rheumatologist 0.90 0.82 0.85 157 urogyn 0.91 0.88 0.90 118 urologist 0.88 0.96 0.91 135 vascular_surgeon 0.94 0.94 0.94 31 accuracy 0.88 3008 macro avg 0.85 0.82 0.83 3008 weighted avg 0.87 0.88 0.87 3008 . /usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) . Let&#39;s take a look at one of the query that our model messed up. Honestly, even I would have gotten confused with that. Perhaps shows the limitation of our dataset preparation method we used. . interp.plot_top_losses(1) . input target predicted probability loss . 0 xxbos xxup ct xxmaj virtual xxmaj colonoscopy i recently has a colonoscopy what it was incomplete due to scar tissue . xxmaj thank goodness my biopsy was negative so no cancer which was the worries i had . xxmaj the doctor said since he could not complete it i would have to go do a xxup ct xxmaj virtual xxmaj colonoscopy . xxmaj has anyone had on | paediatrician | gastroenterologist | 0.9426111578941345 | 11.6873779296875 | . Let&#39;s make some queries and see what our model says. . get_prediction(&#39;lump under my armpit&#39;, learn) . Specialty Probability . 0 breast_surgeon | 70.66 | . 1 cardiologist | 5.14 | . 2 psychiatrist | 4.57 | . 3 oncologist | 3.33 | . 4 plastic_surgeon | 2.71 | . Query lump under my armpit outputs general surgeon with a confidence of 70.66%. That is a good start. . Below we have few more examples. The model prefers descriptive queries which is understandable as that is how it was trained. Seizure as a query gives wrong prediction while a descriptive queries that include seizure predicts correctly. . The word feeling strongly predicts psychiatrist. A descriptive query around feeling does help with better prediciton. . get_prediction(&#39;seizure&#39;, learn) . Specialty Probability . 0 cardiologist | 37.10 | . 1 orthopedic_surgeon | 34.22 | . 2 neurologist | 12.44 | . 3 psychiatrist | 7.14 | . 4 paediatrician | 2.18 | . get_prediction(&#39;i have had seizure 3 times in the past 2 days&#39;, learn) . Specialty Probability . 0 neurologist | 93.13 | . 1 psychiatrist | 6.34 | . 2 orthopedic_surgeon | 0.32 | . 3 infection_disease | 0.10 | . 4 neurosurgeon | 0.05 | . get_prediction(&#39;i am feeling cold&#39;, learn) . Specialty Probability . 0 psychiatrist | 76.58 | . 1 neurologist | 5.19 | . 2 o&amp;g | 4.95 | . 3 orthopedic_surgeon | 3.17 | . 4 otolaryngologist | 2.03 | . get_prediction(&#39;i am feeling cold at night with slight cough and fever&#39;, learn) . Specialty Probability . 0 pulmonologist | 38.52 | . 1 psychiatrist | 26.58 | . 2 neurologist | 7.16 | . 3 otolaryngologist | 4.06 | . 4 allergist | 3.15 | . get_prediction(&#39;knee pain with slight swelling&#39;, learn) . Specialty Probability . 0 orthopedic_surgeon | 80.73 | . 1 rheumatologist | 5.56 | . 2 cardiologist | 5.12 | . 3 neurologist | 3.17 | . 4 internal_medicine | 1.34 | . get_prediction(&#39;my ldl levels are high&#39;, learn) . Specialty Probability . 0 cardiologist | 49.45 | . 1 endocrinologist | 21.16 | . 2 internal_medicine | 10.64 | . 3 nephrologist | 3.21 | . 4 psychiatrist | 2.76 | . We have come to the end of the blog. What is next? . increase the size of dataset | use transformer based model |",
            "url": "https://moarshy.github.io/blogs/nlp/fastai/text%20classification/medical/2021/11/13/_10_29_specialtytextclassification.html",
            "relUrl": "/nlp/fastai/text%20classification/medical/2021/11/13/_10_29_specialtytextclassification.html",
            "date": " • Nov 13, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Understanding Graph Neural Network",
            "content": "My interest lies in using deep learning to address problems in healthcare and medicine. Previously, we have used deep learning to address computer vision problems in healthcare. In this blog, we will learn Graph Neural Network and how it could be used in medicine such as in drug design/drug discovery. . Graph/GNN is new to me and the resources below were of great help in understanding these new concepts. . Resources . https://www.youtube.com/watch?v=fOctJB4kVlM . https://sites.google.com/view/ml-basics/convolution . https://www.youtube.com/watch?v=1miz7yggcTg . What is Graphs? . Networks or graphs are a general language for describing complex systems of interacting entities. In computer science, the graph is a structured data type that consists of nodes/vertices and edges. G = (V,E) Some examples of graph data are1. Social network2. interaction between genes and proteins3. economic network4. communication network5. network of neurons . . For example, let&#39;s assume we are representing a chemical molecule as a graph. We will represent the atoms as nodes and the bonds connecting the atoms as edges. In a social network, the individuals will be represented as nodes and the edges are connections between two individuals.  . Graphs can be directed or non-directed. An example of a directed graph would be representing Twitter data. Individuals are represented as nodes and &quot;following&quot; is represented as edges. Unlike Facebook, Twitter is directed because when Person A follows Person B, Person B need not follow Person A. Hence, this is a directed graph.  . . Some concepts of graph . they are represented as nodes and edges | the edges can be directed | the edges can have weights | nodes and edges can have features to describe them. An example of a node feature for a molecule could be - the number of valence electrons, metallic or not, the atomic number, etc. For edges, it could be the type of bond, the number of bonds, etc. | labels of nodes can be the same, for example when representing NO2, there will be one N and two Os | How to convert a graph into something that the computer can understand? . Adjacency Matrix (A) | An adjacency matrix is an NxN (N=Number of nodes) matrix where the elements indicate connections with 1 and non-connection with 0. It is also called a connection matrix. Adjacency Matrix can be weighted. . Incidence Matrix (I) | A matrix of size NxM where N=number of nodes and M=edges of a graph. Indicates if a node and an edge is an incident or not. If a node and an edge is an incident, it will be 1 otherwise 0. For a directed graph, it is the same except when the arrow is away from the node it is 1 and when the arrow is into the node it is -1. . Degree Matrix (D) | A diagonal matrix that contains information about the number of edges connected to a node. . Laplacian Matrix | L = D-A It is a measure of smoothness of a vertex - i.e how quickly it changes between adjacent vectors . An example of an Incidence Matrix . Source: https://www.youtube.com/watch?v=1miz7yggcTg . Different Types of Graph ML Problems . Source: https://www.youtube.com/watch?v=fOctJB4kVlM . Why we need Graph Neural network? . Why cant we just use general CNN? This is because graph data is different. How are they different? . Size and shape. The size and shape of graph data change within a dataset. This is also true for other data types such as images but they can be addressed by resizing and padding. This is not possible for graph data. . | Isomorphism. Two graphs that look different can be structurally identical. The neural network that deals with graph data, therefore, needs to be permutation invariant. . | Grid structure. Graph data are non-euclidean. For images, there is a fixed grid structure but for graphs the structure is dynamic. Graph&#39;s Euclidean distance can not be clearly defined. . | Node ordering. No fixed node ordering. . | Source: https://www.youtube.com/watch?v=fOctJB4kVlM . Graph Neural Network . Due to the problems described above, we need a different way to work with graph data. . A Graph Convolutional Network (GCN) uses the information from the adjacency matrix and node features to output representation or node embedding for each of the nodes. Each node embeddings contains structural as well as feature information about other nodes in the graph. So the node embedding captures information about other nodes, the connection to this node, and the context in the graph. These node embeddings can be used to make predictions depending on the problem we are trying to solve. The node embeddings are similar to feature maps in CNNs. The embedding size is a hyperparameter similar to feature maps. . Other names for GNN - Geometric NN, representation learning. . The image below captures how, in GCN, the adjacency matric and node features are transformed into Node Embeddings that are used in prediction. This is done through the Message Passing Layers. . Source: https://www.youtube.com/watch?v=fOctJB4kVlM . What is going on in Message Passing Layers? . The approach of gathering information about the target node&#39;s neighboring node and combining them in a certain way to get a new embedding and updating the target node features with these embeddings is called Graph Convolutions. Seen as an extension of the CNN approach to graph data. . . Source: A Comprehensive Survey on Graph Neural Network, Zonghan Wu et. al.,2019 . . As clearly illustrated in the above image by DeepFindr, during message passing, a target node&#39;s neighbouring information is aggregated in a certain way before an update function is used to derive new embeddings for the target node. This is done for all nodes in the graph. A second message passing layer would use the new embeddings to derive new embeddings using the aggregate and update function. Two message passing layers would combine information about a target node&#39;s neighbours as well as its neighbour&#39;s neighbour. We can then use the embeddings to make predictions. The number of message passing layer is a hyperparameter. Using too many messages passing layer would lead to over-smoothing in which case all nodes become indistinguishable from each other. . There are different aggregate and update functions have been proposed. Let’s take a look at a few of the proposed functions. . The different variants of aggregate and update functions . . Source: https://youtu.be/ABCGCf8cJOE . . Hands-on GNN - DeepChem . !curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py import conda_installer conda_installer.install() !/root/miniconda/bin/conda info -e !pip install --pre deepchem . . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 3501 100 3501 0 0 20354 0 --:--:-- --:--:-- --:--:-- 20354 . add /root/miniconda/lib/python3.7/site-packages to PYTHONPATH python version: 3.7.10 fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh done installing miniconda to /root/miniconda done installing rdkit, openmm, pdbfixer added omnia to channels added conda-forge to channels done conda packages installation finished! . # conda environments: # base * /root/miniconda Collecting deepchem Downloading https://files.pythonhosted.org/packages/48/4f/918faea08e6f3e42dd955fd7309912cd01782ee62fc6e3a6047192add238/deepchem-2.6.0.dev20210406183355-py3-none-any.whl (553kB) |████████████████████████████████| 563kB 8.4MB/s Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1) Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (0.22.2.post1) Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;deepchem) (2.8.1) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;deepchem) (2018.9) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;deepchem) (1.15.0) Installing collected packages: deepchem Successfully installed deepchem-2.6.0.dev20210406183355 . DeepChem - a library for life sciences . import deepchem as dc import numpy as np from sklearn.metrics import accuracy_score from sklearn.metrics import confusion_matrix import seaborn as sns import matplotlib.pyplot as plt dc.__version__ . . &#39;2.6.0.dev&#39; . Resources . https://github.com/deepchem/deepchem/tree/master/examples/tutorials . DeepChem offers many different datasets. Let&#39;s take a look at the different datasets. . [method for method in dir(dc.molnet) if &quot;load_&quot; in method ] . . [&#39;load_Platinum_Adsorption&#39;, &#39;load_bace_classification&#39;, &#39;load_bace_regression&#39;, &#39;load_bandgap&#39;, &#39;load_bbbc001&#39;, &#39;load_bbbc002&#39;, &#39;load_bbbp&#39;, &#39;load_cell_counting&#39;, &#39;load_chembl&#39;, &#39;load_chembl25&#39;, &#39;load_clearance&#39;, &#39;load_clintox&#39;, &#39;load_delaney&#39;, &#39;load_factors&#39;, &#39;load_function&#39;, &#39;load_hiv&#39;, &#39;load_hopv&#39;, &#39;load_hppb&#39;, &#39;load_kaggle&#39;, &#39;load_kinase&#39;, &#39;load_lipo&#39;, &#39;load_mp_formation_energy&#39;, &#39;load_mp_metallicity&#39;, &#39;load_muv&#39;, &#39;load_nci&#39;, &#39;load_pcba&#39;, &#39;load_pdbbind&#39;, &#39;load_perovskite&#39;, &#39;load_ppb&#39;, &#39;load_qm7&#39;, &#39;load_qm8&#39;, &#39;load_qm9&#39;, &#39;load_sampl&#39;, &#39;load_sider&#39;, &#39;load_sweet&#39;, &#39;load_thermosol&#39;, &#39;load_tox21&#39;, &#39;load_toxcast&#39;, &#39;load_uspto&#39;, &#39;load_uv&#39;, &#39;load_zinc15&#39;] . Thats a nice list of datasets. You can read more about the available datasets here. For our blog going forward, we will work with the HIV dataset. . About the dataset . The HIV dataset was introduced by the Drug Therapeutics Program (DTP) AIDS Antiviral Screen, which tested the ability to inhibit HIV replication for over 40,000 compounds. Screening results were evaluated and placed into three categories:confirmed inactive (CI),confirmed active (CA) and confirmed moderately active (CM). We further combine the latter two labels, making it a classification task between inactive (CI) and active (CA and CM). . tasks, datasets, transformers = dc.molnet.load_hiv(featurizer=&#39;GraphConv&#39;, splitter=&#39;random&#39;) . DeepChem offers many featurizers that allows us to represent the molecules in different ways. In the above example, we are using GraphConv as the featurizer. This transforms the molecule data in such a way for Graph Convolution Network to use. . tasks . [&#39;HIV_active&#39;] . train, valid, test = datasets . A dataset contains the following - X (the features), y (the targets), w (the weights) . train . &lt;DiskDataset X.shape: (32901,), y.shape: (32901, 1), w.shape: (32901, 1), task_names: [&#39;HIV_active&#39;]&gt; . When we featurize the data using GraphConv, it creates a ConvMol object for each X. Each sample is of a different shape since each molecule has a different number of atoms. . train.X.shape . (32901,) . train.ids . array([&#39;O=S(=O)(OCCSS(=O)(=O)c1ccccc1)c1ccccc1&#39;, &#39;CCNCC(O)c1ccc(N)c([N+](=O)[O-])c1.Cl&#39;, &#39;Cc1c(C(Cc2ccccc2N(C)C(=O)C=CC(=O)O)c2c[nH]c3ccccc23)c2ccccc2n1C&#39;, ..., &#39;NC1=NC(c2ccccc2)=CC=C(c2ccccc2)N=N1&#39;, &#39;OCC1N=C(c2cccs2)OC1c1ccccc1&#39;, &#39;O=C(O)c1cc(S(=O)(=O)Nc2cc(Cc3cc(NS(=O)(=O)c4ccc(O)c(C(=O)O)c4)c(O)c(C(=O)O)c3)cc(C(=O)O)c2O)ccc1O.[NaH]&#39;], dtype=object) . train.X[0] . &lt;deepchem.feat.mol_graphs.ConvMol at 0x7fa0bca4cc10&gt; . We can access the feature data like this. For train.X[0], it is of shape 22 (number of atoms) by 75 (number of features). . first = train.X[0] first.atom_features.shape . (22, 75) . second = train.X[1] second.atom_features.shape . (17, 75) . from rdkit import Chem from rdkit.Chem.Draw import IPythonConsole first_molecule = Chem.MolFromSmiles(train.ids[0]) first_molecule . first_molecule.GetNumAtoms() . 22 . sec_molecule = Chem.MolFromSmiles(train.ids[1]) sec_molecule . sec_molecule.GetNumAtoms() . 17 . Let&#39;s build a GraphConvModel and fit the data. DeepChem provides an easy way to build and train GCN. We could also build our own GCN which we will see later. . n_tasks = len(tasks) model = dc.models.GraphConvModel(n_tasks, mode=&#39;classification&#39;) model.fit(train, nb_epoch=50) . . /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0&#34;, shape=(556,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0&#34;, shape=(556, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0&#34;, shape=(2488,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0&#34;, shape=(2488, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0&#34;, shape=(2598,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0&#34;, shape=(2598, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0&#34;, shape=(244,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0&#34;, shape=(244, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0&#34;, shape=(556,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0&#34;, shape=(556, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0&#34;, shape=(2488,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0&#34;, shape=(2488, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0&#34;, shape=(2598,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0&#34;, shape=(2598, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0&#34;, shape=(244,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0&#34;, shape=(244, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0&#34;, shape=(0, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0&#34;, shape=(0, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_23:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_22:0&#34;, shape=(0, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_25:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_24:0&#34;, shape=(0, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_27:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_26:0&#34;, shape=(0, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_29:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_28:0&#34;, shape=(0, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0&#34;, shape=(556,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0&#34;, shape=(556, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0&#34;, shape=(2488,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0&#34;, shape=(2488, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0&#34;, shape=(2598,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0&#34;, shape=(2598, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0&#34;, shape=(244,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0&#34;, shape=(244, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0&#34;, shape=(536,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0&#34;, shape=(536, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0&#34;, shape=(2392,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0&#34;, shape=(2392, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0&#34;, shape=(2514,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0&#34;, shape=(2514, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_26:0&#34;, shape=(224,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_25:0&#34;, shape=(224, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_29:0&#34;, shape=(6,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_28:0&#34;, shape=(6, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0&#34;, shape=(536,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0&#34;, shape=(536, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0&#34;, shape=(2392,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0&#34;, shape=(2392, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0&#34;, shape=(2514,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0&#34;, shape=(2514, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0&#34;, shape=(224,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0&#34;, shape=(224, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0&#34;, shape=(6,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0&#34;, shape=(6, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0&#34;, shape=(536,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0&#34;, shape=(536, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0&#34;, shape=(2392,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0&#34;, shape=(2392, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0&#34;, shape=(2514,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0&#34;, shape=(2514, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_26:0&#34;, shape=(224,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_25:0&#34;, shape=(224, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_29:0&#34;, shape=(6,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_28:0&#34;, shape=(6, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_26:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_25:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_29:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_28:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_26:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_25:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_29:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_28:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_32:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_31:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_10:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_35:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_34:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_11:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_38:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_37:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_12:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_41:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_40:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_13:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_27:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_26:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_32:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_31:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_10:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_35:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_34:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_11:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_38:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_37:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_12:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_41:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_40:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_13:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_44:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_43:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_14:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_47:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_46:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_15:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_23:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_22:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_44:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_43:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_14:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_47:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_46:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_15:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_50:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_49:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_16:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_53:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_52:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_17:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_25:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_24:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_50:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_49:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_16:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_53:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_52:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_17:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_56:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_55:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_18:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_59:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_58:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_19:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_29:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_28:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_56:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_55:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_18:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_59:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_58:0&#34;, shape=(None, 64), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_19:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) . 0.2921682548522949 . Let&#39;s evaluate our model. Looks like our model overfits. . metric = dc.metrics.Metric(dc.metrics.roc_auc_score) print(&#39;Training set score:&#39;, model.evaluate(train, [metric], transformers)) print(&#39;Test set score:&#39;, model.evaluate(test, [metric], transformers)) . WARNING:tensorflow:5 out of the last 8 calls to &lt;function KerasModel._compute_model at 0x7fa0a92cc950&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for more details. WARNING:tensorflow:6 out of the last 10 calls to &lt;function KerasModel._compute_model at 0x7fa0a92cc950&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for more details. Training set score: {&#39;roc_auc_score&#39;: 0.9867495223607332} Test set score: {&#39;roc_auc_score&#39;: 0.8326334816462736} . preds = model.predict(test).reshape(4113, 2) . accuracy = accuracy_score(test.y.reshape(-1), np.argmax(preds, axis=1)); accuracy . 0.8655482616095308 . cm = confusion_matrix(test.y.reshape(-1), np.argmax(preds, axis=1)) . plt.style.use(&#39;seaborn&#39;) ax= plt.subplot() sns.heatmap(cm, annot=True, ax = ax, cmap=&quot;YlGnBu&quot;, fmt=&quot;&quot;); #annot=True to annotate cells # labels, title and ticks ax.set_xlabel(&#39;Predicted labels&#39;); ax.set_ylabel(&#39;True labels&#39;); ax.set_title(&#39;Confusion Matrix&#39;); ax.xaxis.set_ticklabels([&#39;Inactive&#39;, &#39;Active&#39;]); ax.yaxis.set_ticklabels([&#39;Inactive&#39;, &#39;Active&#39;]); . Let&#39;s build our own model using DeepChem. . from deepchem.models.layers import GraphConv, GraphPool, GraphGather import tensorflow as tf import tensorflow.keras.layers as layers from deepchem.metrics import to_one_hot from deepchem.feat.mol_graphs import ConvMol import numpy as np . . batch_size = 100 class MyGraphConvModel(tf.keras.Model): def __init__(self): super(MyGraphConvModel, self).__init__() self.gc1 = GraphConv(128, activation_fn=tf.nn.tanh) self.batch_norm1 = layers.BatchNormalization() self.gp1 = GraphPool() self.gc2 = GraphConv(128, activation_fn=tf.nn.tanh) self.batch_norm2 = layers.BatchNormalization() self.gp2 = GraphPool() self.gc3 = GraphConv(128, activation_fn=tf.nn.tanh) self.batch_norm3 = layers.BatchNormalization() self.gp3 = GraphPool() self.dense1 = layers.Dense(256, activation=tf.nn.tanh) self.batch_norm3 = layers.BatchNormalization() self.readout = GraphGather(batch_size=batch_size, activation_fn=tf.nn.tanh) self.dense2 = layers.Dense(n_tasks*2) self.logits = layers.Reshape((n_tasks, 2)) self.softmax = layers.Softmax() def call(self, inputs): gc1_output = self.gc1(inputs) batch_norm1_output = self.batch_norm1(gc1_output) gp1_output = self.gp1([batch_norm1_output] + inputs[1:]) gc2_output = self.gc2([gp1_output] + inputs[1:]) batch_norm2_output = self.batch_norm1(gc2_output) gp2_output = self.gp2([batch_norm2_output] + inputs[1:]) gc3_output = self.gc3([gp2_output] + inputs[1:]) batch_norm3_output = self.batch_norm1(gc3_output) gp3_output = self.gp3([batch_norm3_output] + inputs[1:]) dense1_output = self.dense1(gp3_output) batch_norm3_output = self.batch_norm3(dense1_output) readout_output = self.readout([batch_norm3_output] + inputs[1:]) logits_output = self.logits(self.dense2(readout_output)) return self.softmax(logits_output) . model = dc.models.KerasModel(MyGraphConvModel(), loss=dc.models.losses.CategoricalCrossEntropy()) . Let&#39;s create a data gererator function and see what is going on in it. . def data_generator(dataset, epochs=1): for ind, (X_b, y_b, w_b, ids_b) in enumerate(dataset.iterbatches(batch_size, epochs, deterministic=False, pad_batches=True)): multiConvMol = ConvMol.agglomerate_mols(X_b) inputs = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)] for i in range(1, len(multiConvMol.get_deg_adjacency_lists())): inputs.append(multiConvMol.get_deg_adjacency_lists()[i]) labels = [to_one_hot(y_b.flatten(), 2).reshape(-1, n_tasks, 2)] weights = [w_b] yield (inputs, labels, weights) . for ind, (X_b, y_b, w_b, ids_b) in enumerate(train.iterbatches(20, 1, deterministic=True, pad_batches=True)): multiConvMol = ConvMol.agglomerate_mols(X_b) inputs = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)] for i in range(1, len(multiConvMol.get_deg_adjacency_lists())): inputs.append(multiConvMol.get_deg_adjacency_lists()[i]) labels = [to_one_hot(y_b.flatten(), 2).reshape(-1, n_tasks, 2)] weights = [w_b] break . The data generator function yield inputs, labels and weights. Labels and weights are straightforward hence let’s break down the inputs. The length of inputs is 13. . len(inputs) . 13 . The first item is the atom_features. It is of shape (495, 75). We are batching 20 molecules, hence the total number of atoms in these 20 molecules is 495. 75 is the feature embedding size. . inputs[0], inputs[0].shape . (array([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 1., ..., 0., 0., 0.], [0., 0., 1., ..., 0., 0., 0.], ..., [1., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]]), (495, 75)) . The second item in inputs is the deg_slice. deg_slice is a convenient indexing function. Later, we will see that the degree (which indicates the number of connections each atom makes) adjacency list is grouped by their degree i.e. all atoms with 1 degree for all the 20 molecules are grouped together and all atoms with 2 degrees are grouped together and so on. The atoms on the atom_features are also arranged by their degree. The deg_slice indicates where the different degrees start and ends. For eg, a degree of 1 starts from index 1 and ends at index 93 while the degree of 2 starts from index 94 and ends at index 228. . multiConvMol.deg_slice . array([[ 0, 1], [ 1, 93], [ 94, 228], [322, 163], [485, 8], [493, 2], [495, 0], [495, 0], [495, 0], [495, 0], [495, 0]]) . The next item in the inputs is the membership of each atoms. It indicates to which molecule each atom belongs. . inputs[2] . array([ 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 7, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 13, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 0, 0, 4, 8, 10, 13, 14, 15, 6, 6], dtype=int32) . sum(np.array(multiConvMol.membership) == 0) . 22 . sum(np.array(multiConvMol.membership) == 1) . 17 . Items 4 onwards is the deg_adjacency_lists. 4th item is the 0 degree atoms, 5th item is the 1 degree atoms and so on. . len(multiConvMol.get_deg_adjacency_lists()) . 11 . multiConvMol.get_deg_adjacency_lists()[1] . array([[485], [485], [486], [486], [324], [328], [326], [326], [108], [333], [340], [337], [337], [339], [332], [139], [346], [352], [135], [151], [360], [355], [365], [365], [369], [369], [191], [383], [383], [385], [386], [197], [389], [388], [388], [221], [212], [393], [224], [489], [404], [412], [489], [408], [411], [489], [406], [405], [413], [412], [415], [414], [416], [418], [421], [419], [426], [427], [431], [424], [433], [428], [435], [271], [491], [270], [269], [491], [266], [442], [443], [444], [492], [448], [445], [285], [280], [459], [461], [462], [457], [464], [458], [473], [470], [309], [471], [472], [316], [318], [482], [479], [478]], dtype=int32) . model.fit_generator(data_generator(train, epochs=50)) . . /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_14:0&#34;, shape=(459,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_13:0&#34;, shape=(459, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_17:0&#34;, shape=(2828,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_16:0&#34;, shape=(2828, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_20:0&#34;, shape=(2667,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_19:0&#34;, shape=(2667, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_23:0&#34;, shape=(240,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_22:0&#34;, shape=(240, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_11:0&#34;, shape=(459,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_10:0&#34;, shape=(459, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_13:0&#34;, shape=(2828,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_12:0&#34;, shape=(2828, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_1:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_15:0&#34;, shape=(2667,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_14:0&#34;, shape=(2667, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_2:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_17:0&#34;, shape=(240,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_16:0&#34;, shape=(240, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_3:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_19:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_18:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_21:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_20:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_23:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_22:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_25:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_24:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_27:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_26:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_29:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_28:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_14:0&#34;, shape=(459,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_13:0&#34;, shape=(459, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_17:0&#34;, shape=(2828,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_16:0&#34;, shape=(2828, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_20:0&#34;, shape=(2667,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_19:0&#34;, shape=(2667, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_23:0&#34;, shape=(240,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_22:0&#34;, shape=(240, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_11:0&#34;, shape=(459,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_10:0&#34;, shape=(459, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_13:0&#34;, shape=(2828,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_12:0&#34;, shape=(2828, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_1:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_15:0&#34;, shape=(2667,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_14:0&#34;, shape=(2667, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_2:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_17:0&#34;, shape=(240,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_16:0&#34;, shape=(240, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_3:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_19:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_18:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_21:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_20:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_23:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_22:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_25:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_24:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_27:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_26:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_29:0&#34;, shape=(0,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_28:0&#34;, shape=(0, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_14:0&#34;, shape=(459,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_13:0&#34;, shape=(459, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_17:0&#34;, shape=(2828,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_16:0&#34;, shape=(2828, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_20:0&#34;, shape=(2667,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_19:0&#34;, shape=(2667, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_23:0&#34;, shape=(240,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_22:0&#34;, shape=(240, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_14:0&#34;, shape=(501,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_13:0&#34;, shape=(501, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_17:0&#34;, shape=(2510,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_16:0&#34;, shape=(2510, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_20:0&#34;, shape=(2313,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_19:0&#34;, shape=(2313, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_11:0&#34;, shape=(501,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_10:0&#34;, shape=(501, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_13:0&#34;, shape=(2510,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_12:0&#34;, shape=(2510, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_1:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_15:0&#34;, shape=(2313,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_14:0&#34;, shape=(2313, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_2:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_14:0&#34;, shape=(501,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_13:0&#34;, shape=(501, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_17:0&#34;, shape=(2510,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_16:0&#34;, shape=(2510, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_20:0&#34;, shape=(2313,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_19:0&#34;, shape=(2313, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_11:0&#34;, shape=(501,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_10:0&#34;, shape=(501, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_13:0&#34;, shape=(2510,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_12:0&#34;, shape=(2510, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_1:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_15:0&#34;, shape=(2313,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_14:0&#34;, shape=(2313, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_2:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_14:0&#34;, shape=(501,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_13:0&#34;, shape=(501, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_17:0&#34;, shape=(2510,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_16:0&#34;, shape=(2510, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_20:0&#34;, shape=(2313,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_19:0&#34;, shape=(2313, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_17:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_16:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_20:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_19:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_23:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_22:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_26:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_25:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_29:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_28:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_11:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_10:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_13:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_12:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_1:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_15:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_14:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_2:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_17:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_16:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_3:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_19:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_18:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_17:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_16:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_20:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_19:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_23:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_22:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_26:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_25:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_29:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_28:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_11:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_10:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_13:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_12:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_1:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_15:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_14:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_2:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_17:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_16:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_3:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_19:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_18:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_4:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_17:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_16:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_20:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_19:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_23:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_22:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_26:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_25:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_29:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_28:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_32:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_31:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_10:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_35:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_34:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_11:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_38:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_37:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_12:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_41:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_40:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_13:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_44:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_43:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_14:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_47:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_46:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_15:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_21:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_20:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_25:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_24:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_27:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_26:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_32:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_31:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_10:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_35:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_34:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_11:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_38:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_37:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_12:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_41:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_40:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_13:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_44:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_43:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_14:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_47:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_46:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_15:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_21:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_20:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_5:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_25:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_24:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_7:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_27:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_26:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_8:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_32:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_31:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_10:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_35:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_34:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_11:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_38:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_37:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_12:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_41:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_40:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_13:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_44:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_43:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_14:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_47:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_46:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_15:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) . WARNING:tensorflow:5 out of the last 16393 calls to &lt;function KerasModel._create_gradient_fn.&lt;locals&gt;.apply_gradient_for_batch at 0x7fa0a06b2ef0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for more details. . /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_50:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_49:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_16:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_53:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_52:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_17:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_29:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_28:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_50:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_49:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_16:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_53:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_52:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_17:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_29:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_28:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_9:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_50:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_49:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_16:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_53:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_52:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_17:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_56:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_55:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_18:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_59:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Reshape_58:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_4/Cast_19:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_23:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Reshape_22:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_4/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_56:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_55:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_18:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_59:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Reshape_58:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_3/Cast_19:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_23:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Reshape_22:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_conv_3/Cast_6:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_56:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_55:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_18:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_59:0&#34;, shape=(None,), dtype=int32), values=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Reshape_58:0&#34;, shape=(None, 128), dtype=float32), dense_shape=Tensor(&#34;gradient_tape/my_graph_conv_model/graph_pool_2/Cast_19:0&#34;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;shape. This may consume a large amount of memory.&#34; % value) . 0.6231404113769531 . print(&#39;Training set score:&#39;, model.evaluate_generator(data_generator(train), [metric], transformers)) print(&#39;Test set score:&#39;, model.evaluate_generator(data_generator(test), [metric], transformers)) . WARNING:tensorflow:5 out of the last 375 calls to &lt;function KerasModel._compute_model at 0x7fa0bff2a4d0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for more details. Training set score: {&#39;roc_auc_score&#39;: 0.7272946114084287} Test set score: {&#39;roc_auc_score&#39;: 0.6715548288953609} . So our model did poorly than the previous DeepChem&#39;s factory method. Likely for this task 2 message passing layer is better. This concludes this blog. I plan to continue my DeepChem journey. Things I plan to do in my future blogs. . Understand and use different featurizers and their corresponding models such as the WeaveFeaturizer and WeaveModel | Work with different MolNet datasets | Understand the library at a deeper level such as what goes on in GraphConvModel, fit methods |",
            "url": "https://moarshy.github.io/blogs/gnn/gcn/drug%20design/2021/04/14/basicgnnblog.html",
            "relUrl": "/gnn/gcn/drug%20design/2021/04/14/basicgnnblog.html",
            "date": " • Apr 14, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Self-supervised learning and soft-labeling for Image Classification",
            "content": "In this blog, we will learn/apply self-supervised learning and soft-label/pseudo-labelling technique to tackle the plant pathology Kaggle competition. I was introduced to soft-labeling when I came across this amazing blog by Isaac Flath. About the same time, I came across Jeremy&#39;s blog on self-supervised learning (SSL). Both the techniques were interesting and I feel going forward these techniques are going to be important techniques in computer vision. Hence, I decided to blog my learnings of these intriguing techniques. . A word on the dataset . For this blog, we will be using the Plant Pathology dataset. The task at hand is to classify images of different plant diseases. . There are some challenges with the dataset . Imbalanced data - one of the class contains very few samples | Mislabeled data - the other issue with this dataset is that the labels are noisy/mislabeled. The winner of this competition used soft-labelling in the winning model | We will do this in two parts . Self-supervised learning . What is self-supervised learning | Different types of self-supervised learning | Applying rotation-based learning (rotnet) | Applying SimCLR learning | | Soft-labeling | pseudo-laebling . Generating pseudo-label using transfer learning from rotnet model, SimCLR model | Final task (downstream task) to predict plant diseases using transfer learning (using the model trained in part 1) and soft-labeling/progressive pseudo-labelling | | Part 1: Self-Supervised Learning . What is Self-supervised learning? . Supervised learning has brought tremendous success to the field of computer vision. Although supervised learning requires huge amount of data, by using transfer learning one could reduce the requirement of data by about 1000x. . Largely, models for transfer learning are trained using the ImageNet dataset which were trained on 1.4 million images of 1000 different classes. Sometimes, for some domain, such as medical images, transfer learning from ImageNet might not work that well. Given this constraint, and the fact that generating labels for large amount of data in this domain is costly, self-supervised learning (SSL) has proven to be effective. In SSL, unlabeled data is trained in a supervised manner. . So what is self-supervised learning? SSL make use of the labels that are naturally part of the input data. SSL has been widely used in NLP tasks. Training a language model often involves predicting the next word of a sentence. The label for the language model, the next word, is a natural part of the input data. While learning to predict the next word, the model must have learnt a bit about the nature of language. Now, such training are common in most NLP tasks. . In computer vision, SSL starts with &quot;pretext tasks&quot;. In &quot;pretext task&quot;, we train a model from scratch using labels that comes naturally with the input data. Once pretrained, fine-tuning can be carried out on the &quot;downstream tasks&quot;. . Further Readings . https://www.fast.ai/2020/01/13/self_supervised/ . https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html . Different ways of doing self-supervised learning . Different techniques of SSL can be categorized into three . Pretext task based . Relative positioning | Colorization | Rotation | Multiple pretext | Jigsaw puzzle | | Generative model based . Autoencoders | Split brain autoencoder | Neural scene representation | Context encoder | Semantic inpainting | BiGAN | | Discriminative based contrastive learning . SimCLR | SimCLR2 | MoCo | MoCo v2 | BYOL | SwAV | | SSL and different techniques were well explained in this lecture series by Anuj Shah. Taking a look a the SOTA page for SSL on PapersWithCode. The discriminative based contrastive learning are leading the pack. . Rotation-based pretext tasks . In this pretext task, we rotate the image by certain degrees (0, 90, 180 and 270) and train the model to predict which degree of rotation was applied. While learning to classify the degree of rotation, the model learns many semantic concepts. . (Image source: Gidaris et al. 2018) https://arxiv.org/abs/1803.07728 . Now, let&#39;s take a look how we can apply this pretext task using fastai. For a more detailed explanation, please refer to this amazing blog by Amar Saini. . from fastai.vision.all import * from fastai.vision.learner import _update_first_layer import timm import torchvision . . path = Path(&#39;/content/drive/MyDrive/colab_notebooks/fastai/plant_pathology/data&#39;) path_img = path/&#39;images&#39; train = pd.read_csv(path/&#39;train.csv&#39;) train.head(5) . . We will use seresnext50_32x4d from timm model as the architecture of choice. . def create_timm_body(arch:str, pretrained=False, cut=None, n_in=3): &quot;Creates a body from any model in the `timm` library.&quot; model = timm.create_model(arch, pretrained=pretrained, num_classes=0, global_pool=&#39;&#39;) _update_first_layer(model, n_in, pretrained) if cut is None: ll = list(enumerate(model.children())) cut = next(i for i,o in reversed(ll) if has_pool_type(o)) if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut]) elif callable(cut): return cut(model) else: raise NamedError(&quot;cut must be either integer or function&quot;) . arch = create_timm_body(&#39;seresnext50_32x4d&#39;) nf = num_features_model(arch) head = create_head(nf, 4, concat_pool=True) net = nn.Sequential(arch, head) . tensorToImage = torchvision.transforms.ToPILImage() imageToTensor = torchvision.transforms.ToTensor() . Once we have selected the encoder/base architecture, it&#39;s time to build our PyTorch style dataset. There is nothing fancy going on here except each training example is rotated randomly by 0, 90, 180 or 270 degrees. The degree of rotation will also be used as the label. . class Custom_Dataset_PP(): # Codes from Amar Saini&#39;s (__Epoching__) blog def __init__(self, fns): self.fns = fns def __len__(self): return len(self.fns) def __getitem__(self, idx): # 4 classes for rotation degrees = [0, 90, 180, 270] rand_choice = random.randint(0, len(degrees)-1) img = PILImage.create(self.fns[idx]) img = img.resize((256, 256)) img = img.rotate(degrees[rand_choice]) img = imageToTensor(img) return img, torch.tensor(rand_choice).long() def show_batch(self, n=3): fig, axs = plt.subplots(n, n, figsize=(12,10)) fig.tight_layout() for i in range(n): for j in range(n): rand_idx = random.randint(0, len(self)-1) img, label = self.__getitem__(rand_idx) axs[i, j].imshow(tensorToImage(img), cmap=&#39;gray&#39;) axs[i, j].set_title(&#39;Label: {0} ({1} Degrees)&#39;.format(label.item(), label.item()*90)) axs[i, j].axis(&#39;off&#39;) ds = Custom_Dataset_PP(path_img.ls()) . . As we can see from the show_batch, the rotation based pretext task might not be good for this dataset as leaves can exist in any orientations. But our objective is to learn hence this is still a good practice. . ds.show_batch() . From here, we use standard fastai practice to train the model. . split = int(len(path_img.ls())*0.8) train_fns = path_img.ls()[:split] valid_fns = path_img.ls()[split:] train_ds = Custom_Dataset_PP(train_fns) valid_ds = Custom_Dataset_PP(valid_fns) dls = DataLoaders.from_dsets(train_ds, valid_ds).cuda() . learn = Learner(dls, net, loss_func=CrossEntropyLossFlat(), splitter=default_split, metrics=accuracy) . learn.fit_one_cycle(25, 1e-4) . epoch train_loss valid_loss accuracy time . 0 | 1.569923 | 1.409840 | 0.271635 | 06:39 | . 1 | 1.523075 | 1.378337 | 0.320913 | 03:21 | . 2 | 1.461118 | 1.298200 | 0.352163 | 03:20 | . 3 | 1.364290 | 1.330265 | 0.362981 | 03:21 | . 4 | 1.270127 | 1.191683 | 0.418269 | 03:20 | . 5 | 1.204014 | 2.085269 | 0.301683 | 03:19 | . 6 | 1.129306 | 1.249018 | 0.411058 | 03:19 | . 7 | 1.054507 | 1.541547 | 0.355769 | 03:18 | . 8 | 0.996718 | 2.167537 | 0.304087 | 03:20 | . 9 | 0.930008 | 2.989300 | 0.269231 | 03:20 | . 10 | 0.888594 | 0.878343 | 0.522837 | 03:19 | . 11 | 0.852690 | 0.867087 | 0.533654 | 03:20 | . 12 | 0.810870 | 0.848070 | 0.554087 | 03:20 | . 13 | 0.786548 | 1.054648 | 0.491587 | 03:21 | . 14 | 0.739632 | 1.170150 | 0.473558 | 03:21 | . 15 | 0.707019 | 0.832262 | 0.542067 | 03:21 | . 16 | 0.671642 | 0.802649 | 0.585337 | 03:21 | . 17 | 0.653890 | 0.827771 | 0.569712 | 03:21 | . 18 | 0.621239 | 1.211577 | 0.491587 | 03:20 | . 19 | 0.600797 | 0.804843 | 0.573317 | 03:22 | . 20 | 0.581002 | 0.796838 | 0.580529 | 03:21 | . 21 | 0.564937 | 0.779816 | 0.587740 | 03:20 | . 22 | 0.564841 | 0.760423 | 0.579327 | 03:20 | . 23 | 0.549947 | 0.773734 | 0.584135 | 03:20 | . 24 | 0.533107 | 0.759421 | 0.608173 | 03:20 | . We will save the weights of the encoader. . torch.save(learn.model[0], f&#39;{path}/seresnext50_32x4d_rotnetencoader.pth&#39;) . SimCLR: A Simple Framework for Contrastive Learning of Visual Representation . As we saw earlier in PapersWithCode SOTA page for SSL, discriminative based contrastive learning are among the most successful SSL techniques. SimCLR is one among these techniques that was introduced by Google Research. . Before we go further, let’s take a look at the definition of contrastive learning? . What is contrastive learning? It is a SSL technique to learn features of a dataset without labels by teaching the model which data points are similar and which are different. . The SimCLR framework proposes four key components for contrastive learning . Data Augmentation . Here, an image is randomly transformed into two correlated views. This forms a positive pair. SimCLR sequentially applies the following augmentations - random cropping, followed by resize back to the original size, random color distortions and random Gaussian blur. Two views coming from the same image would form a positive pair while two views coming from different image would form a negative pair. . | A neural network base encoder . A model backbone that extracts the feature maps. In our case, we will be using seresnext50_32x4d from timm . | Neural network projection head . This maps the feature maps into a vector space representation where the contrastive loss will be applied. Multilayer perceptron with single linear layer was used in the original paper. . | Contrastive loss . A loss function designed to evaluate how good a job the network is at picking up positive pairs and negative pairs. . | Let&#39;s apply SimCLR in fastai using this self-supervised library by Kerem Turgutlu. . from self_supervised.simclr import * . . First, lets make a general dataloader as per usual. . train[&#39;labels&#39;] = train.iloc[:, 1:].idxmax(axis=1) . fns = train.image_id.values . def label_fn(fn): return train[train[&#39;image_id&#39;] == fn][&#39;labels&#39;].values[0] label_fn(fns[0]) . &#39;scab&#39; . sz = 256 ds = Datasets(fns, [[lambda x: f&#39;{path_img}/{x}.jpg&#39;, PILImage.create], [label_fn, Categorize()]], splits=RandomSplitter()(fns)) dls = ds.dataloaders(bs=32, after_item=[ToTensor(), Resize(sz), IntToFloatTensor()]) . dls.show_batch() . Next, we will make the model which would include an encoader and a projection head. For this we will make use of self-supervised library with some changes. The encoader will come from timm and then attach the projection head to the encoader. . def create_timm_body(arch:str, pretrained=False, cut=None, n_in=3): &quot;Creates a body from any model in the `timm` library.&quot; model = timm.create_model(arch, pretrained=pretrained, num_classes=0, global_pool=&#39;&#39;) _update_first_layer(model, n_in, pretrained) if cut is None: ll = list(enumerate(model.children())) cut = next(i for i,o in reversed(ll) if has_pool_type(o)) if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut]) elif callable(cut): return cut(model) else: raise NamedError(&quot;cut must be either integer or function&quot;) . class MLP(Module): &quot;MLP module as described in paper&quot; def __init__(self, dim, concat_pool=True, projection_size=128, hidden_size=256): self.pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1) self.flatten = Flatten() self.net = nn.Sequential( nn.Linear(dim, hidden_size), nn.ReLU(inplace=True), nn.Linear(hidden_size, projection_size) ) def forward(self, x): x = self.pool(x) x = self.flatten(x) x = self.net(x) return x . def create_simclr_model(arch=resnet50, n_in=3, pretrained=False, cut=None, concat_pool=True, hidden_size=256, projection_size=128): &quot;Create SimCLR from a given arch&quot; encoder = create_timm_body(arch, pretrained, cut, n_in) with torch.no_grad(): representation = encoder(torch.randn((2, n_in, 128, 128))) projector = MLP(representation.size(1)*2, projection_size, hidden_size=hidden_size) apply_init(projector) return SimCLRModel(encoder, projector) . model = create_simclr_model(&#39;seresnext50_32x4d&#39;, pretrained=False) . Once we have the dataloader and the model, we will make a learner. The learner use a SimCLRLoss and SimCLR callback function. We will look at these codes to understand what is going on. . learn = Learner(dls, model, SimCLRLoss(temp=0.5), cbs=[SimCLR(size=128, color=False, stats=None)]) . Below we have the codes for the SimCLR callback. The callback upon initiation makes two augmentation function - aug1 and aug2. These will be used to make the two views of the same input image. As you can see from the get_aug_pipe function the augmentation uses RandomResizedCrop, RandomHorizontalFlip, ColorJitter, and RandomGrayscale. The callback before_batch makes the two images, concats them and use that as the inputs. The labels are also changed. Assuming the initial batch_size of 5, the labels would be [5, 6, 7, 8, 9, 0, 1, 2, 3, 4]. The first image is positive pair of 5th image, the second image is positive pair of 6th image, and so on. . def get_aug_pipe(size, stats=imagenet_stats, s=.6, color=True, xtra_tfms=[]): &quot;SimCLR augmentations&quot; tfms = [] tfms += [kornia.augmentation.RandomResizedCrop((size, size), scale=(0.2, 1.0), ratio=(3/4, 4/3))] tfms += [kornia.augmentation.RandomHorizontalFlip()] if color: tfms += [kornia.augmentation.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)] if color: tfms += [kornia.augmentation.RandomGrayscale(p=0.2)] tfms += xtra_tfms if stats is not None: tfms += [Normalize.from_stats(*stats)] pipe = Pipeline(tfms) pipe.split_idx = 0 return pipe . class SimCLR(Callback): &quot;SimCLR callback&quot; def __init__(self, size=256, **aug_kwargs): self.aug1 = get_aug_pipe(size, **aug_kwargs) self.aug2 = get_aug_pipe(size, **aug_kwargs) def before_batch(self): xi,xj = self.aug1(self.x), self.aug2(self.x) self.learn.xb = (torch.cat([xi, xj]),) bs = self.learn.xb[0].shape[0] self.learn.yb = (torch.arange(bs, device=self.dls.device).roll(bs//2),) def show_one(self): xb = TensorImage(self.learn.xb[0]) bs = len(xb)//2 i = np.random.choice(bs) xb = self.aug1.decode(xb.to(&#39;cpu&#39;).clone()).clamp(0,1) images = [xb[i], xb[bs+i]] show_images(images) . b = dls.one_batch() learn._split(b) learn(&#39;before_batch&#39;) . The modified image inputs; the initial batch of 32 is doubled. . learn.xb[0].shape . torch.Size([64, 3, 128, 128]) . Let&#39;s take a look at the modified labels. . learn.yb[0] . tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], device=&#39;cuda:0&#39;) . Now that we have taken a look at the callback, lets take a look at the loss function. . class SimCLRLoss(Module): &quot;SimCLR loss function&quot; def __init__(self, temp=0.1): self.temp = temp def forward(self, inp, targ): bs,feat = inp.shape csim = F.cosine_similarity(inp, inp.unsqueeze(dim=1), dim=-1)/self.temp csim = remove_diag(csim) targ = remove_diag(torch.eye(targ.shape[0], device=inp.device)[targ]).nonzero()[:,-1] return F.cross_entropy(csim, targ) . The loss function calculates the cosine_similarity of the vector representation from the projection head and then divides it by the hyperparameter temp. We remove the diagonals from the cosine similarity and the targets. Then we calculate the cross_entropy. . Let&#39;s fit_one_cycle. . learn.fit_one_cycle(25, 1e-4) . epoch train_loss valid_loss time . 0 | 4.004565 | 4.004914 | 01:20 | . 1 | 3.730691 | 3.483200 | 01:21 | . 2 | 3.505424 | 3.356370 | 01:21 | . 3 | 3.350685 | 3.181578 | 01:21 | . 4 | 3.256876 | 3.138497 | 01:21 | . 5 | 3.188638 | 3.078935 | 01:21 | . 6 | 3.124358 | 3.023555 | 01:22 | . 7 | 3.088448 | 3.021066 | 01:22 | . 8 | 3.056739 | 3.010895 | 01:21 | . 9 | 3.032721 | 3.060869 | 01:21 | . 10 | 3.009059 | 3.009850 | 01:22 | . 11 | 2.992094 | 2.977447 | 01:22 | . 12 | 2.992314 | 2.997800 | 01:21 | . 13 | 2.974692 | 3.005455 | 01:21 | . 14 | 2.962943 | 2.972467 | 01:22 | . 15 | 2.954012 | 2.910474 | 01:21 | . 16 | 2.947802 | 2.915481 | 01:21 | . 17 | 2.944147 | 2.911163 | 01:21 | . 18 | 2.933424 | 2.912643 | 01:21 | . 19 | 2.931176 | 2.908795 | 01:21 | . 20 | 2.928176 | 2.912873 | 01:21 | . 21 | 2.927793 | 2.922826 | 01:21 | . 22 | 2.928530 | 2.908896 | 01:21 | . 23 | 2.922103 | 2.900265 | 01:21 | . 24 | 2.918781 | 2.921983 | 01:22 | . Similar to out rotnet, we will save the weights of the encoader. . torch.save(learn.model.encoder, f&#39;{path}/seresnext50_32x4d_simclrencoader.pth&#39;) . Part 2: Softlabelling . Now that we have pre-trained our network using SSL techniques, we will move on to the downstream task. For our downstream task, we will also use soft-labeling to help our training. . Soft-labeling is very helpful in cases where the labels are noisy. The dataset we have been using, Plant Pathology, suffers from noisy labels. The winning solution for this competition used soft-labeling. I came across soft-labeling through Isaac&#39;s blog. For more comprehensive application of soft-labeling, please refer to Isaac&#39;s blog. . We will do this part in two steps . Step 1: Generating soft-labels . Step 2: Applying soft-labels in the downstream task . Generating softlabels . from sklearn.model_selection import StratifiedKFold . . So to apply soft-labeling, we will have to generate the pseudo-labels. We will use SSL trained models to generate our pseudo-labels. The following is the steps to make pseudo-labels. . Create kfold. In our case, we will use k=2 | Train the model using SSL trained weights and fit on the training data with the given labels | After sufficient training, we will generate prediction on the valid set. The prediction will be used as the pseudo-labels | Repeat step 2 and 3 for all different k valid sets | train.head(3) . image_id healthy multiple_diseases rust scab . 0 Train_0 | 0 | 0 | 0 | 1 | . 1 Train_1 | 0 | 1 | 0 | 0 | . 2 Train_2 | 1 | 0 | 0 | 0 | . train[&#39;labels&#39;] = train.iloc[:, 1:].idxmax(1) . N_FOLDS = 2 train[&#39;fold&#39;] = -1 strat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=42, shuffle=True) for i, (_, test_index) in enumerate(strat_kfold.split(train.image_id.values, train[&#39;labels&#39;].values)): train.iloc[test_index, -1] = i train[&#39;fold&#39;] = train[&#39;fold&#39;].astype(&#39;int&#39;) . def get_dls(df, size, fold, bs): batch_tfms = [Normalize.from_stats(*imagenet_stats)] dblock = DataBlock(blocks=(ImageBlock, CategoryBlock), splitter=IndexSplitter(df.loc[df.fold==fold].index), getters=[ ColReader(&#39;image_id&#39;, pref=path/&#39;images&#39;, suff=&#39;.jpg&#39;), ColReader(&#39;labels&#39;) ], item_tfms=[RandomResizedCrop(size, min_scale=0.35), FlipItem(0.5)], batch_tfms=batch_tfms) return dblock.dataloaders(df, bs=bs) . def get_model(df, rotnet=True): if rotnet: arch = create_timm_body(&#39;seresnext50_32x4d&#39;) torch.load(f&#39;{path}/seresnext50_32x4d_rotnetencoader.pth&#39;) head = create_head(num_features_model(arch), df[&#39;labels&#39;].nunique()) apply_init(head) model = nn.Sequential(arch, head) else: arch = create_timm_body(&#39;seresnext50_32x4d&#39;) torch.load(f&#39;{path}/seresnext50_32x4d_simclrencoader.pth&#39;) head = create_head(num_features_model(arch), df[&#39;labels&#39;].nunique()) apply_init(head) model = nn.Sequential(arch, head) return model . splits, preds, targs, preds_c, = [],[],[],[] items = pd.DataFrame(columns = train.columns) for i in range(N_FOLDS): dls = get_dls(train, 228, i, bs=16) model = get_model(train, rotnet=False) learn = Learner(dls, model, metrics=[accuracy, RocAuc()]) learn.fine_tune(15, reset_opt=True) # store predictions p, t, c = learn.get_preds(ds_idx=1, with_decoded=True) preds.append(p); targs.append(t); preds_c.append(c); items = pd.concat([items, dls.valid.items]) . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 2.245435 | 2.073756 | 0.407245 | 0.591565 | 01:27 | . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 1.630546 | 1.246244 | 0.506037 | 0.681683 | 01:28 | . 1 | 1.536798 | 1.205274 | 0.535675 | 0.697780 | 01:27 | . 2 | 1.576910 | 1.541064 | 0.473106 | 0.684111 | 01:27 | . 3 | 1.486408 | 1.448349 | 0.553238 | 0.696692 | 01:27 | . 4 | 1.408332 | 1.150345 | 0.531284 | 0.731727 | 01:27 | . 5 | 1.292639 | 0.882109 | 0.663008 | 0.804221 | 01:26 | . 6 | 1.103595 | 1.071286 | 0.611416 | 0.795798 | 01:28 | . 7 | 0.991075 | 0.743046 | 0.710209 | 0.824435 | 01:28 | . 8 | 0.845321 | 0.623146 | 0.765093 | 0.851047 | 01:27 | . 9 | 0.790943 | 0.619872 | 0.750823 | 0.874319 | 01:31 | . 10 | 0.686515 | 0.568958 | 0.791438 | 0.891836 | 01:28 | . 11 | 0.655953 | 0.519997 | 0.818880 | 0.897981 | 01:30 | . 12 | 0.597022 | 0.477010 | 0.830955 | 0.910269 | 01:28 | . 13 | 0.531461 | 0.475933 | 0.829857 | 0.908447 | 01:27 | . 14 | 0.502115 | 0.476578 | 0.828760 | 0.906857 | 01:27 | . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 2.179506 | 2.657610 | 0.390110 | 0.607213 | 01:26 | . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 1.620119 | 1.272247 | 0.509890 | 0.683388 | 01:26 | . 1 | 1.551659 | 1.186581 | 0.525275 | 0.723610 | 01:25 | . 2 | 1.457448 | 1.184272 | 0.515385 | 0.723678 | 01:24 | . 3 | 1.449472 | 1.069529 | 0.583516 | 0.748897 | 01:27 | . 4 | 1.385499 | 1.160630 | 0.567033 | 0.734892 | 01:26 | . 5 | 1.177015 | 1.050339 | 0.606593 | 0.790950 | 01:25 | . 6 | 1.101527 | 0.718146 | 0.713187 | 0.833402 | 01:25 | . 7 | 1.001735 | 0.937197 | 0.668132 | 0.813787 | 01:25 | . 8 | 0.915719 | 0.711719 | 0.735165 | 0.857576 | 01:26 | . 9 | 0.798974 | 0.606332 | 0.772527 | 0.870674 | 01:26 | . 10 | 0.707872 | 0.535294 | 0.794505 | 0.914215 | 01:26 | . 11 | 0.652735 | 0.533704 | 0.804396 | 0.901796 | 01:25 | . 12 | 0.597695 | 0.484282 | 0.832967 | 0.915541 | 01:25 | . 13 | 0.559858 | 0.475080 | 0.826374 | 0.920336 | 01:25 | . 14 | 0.542785 | 0.470118 | 0.825275 | 0.920716 | 01:24 | . imgs = L(o for o in items.image_id.values) y_true = L(o for o in items.labels.values) y_targ = L(dls.vocab[o] for o in torch.cat(targs)) y_pred = L(dls.vocab[o] for o in torch.cat(preds_c)) p_max = torch.cat(preds).max(dim=1)[0] . res = pd.DataFrame({&#39;imgs&#39;:imgs,&#39;y_true&#39;:y_true,&#39;y_pred&#39;:y_pred}).set_index(&#39;imgs&#39;) print(res.shape) print(train.shape) res.sample(5) . (1821, 2) (1821, 7) . y_true y_pred . imgs . Train_1305 scab | scab | . Train_544 healthy | healthy | . Train_1286 healthy | healthy | . Train_814 rust | rust | . Train_1694 healthy | healthy | . res.to_csv(f&#39;{path}/train_simclr_sl.csv&#39;) . Final downstream tasks . For our final task, we will train using the SSL trained models and use the pseudolebels we generated to &#39;reduce&#39; the impact of nosiy labels. . # dataframe with softlabels rotnet_df = pd.read_csv(f&#39;{path}/train_rotnet_sl.csv&#39;) simclr_df = pd.read_csv(f&#39;{path}/train_simclr_sl.csv&#39;) . rotnet_df.columns = [&#39;image_id&#39;, &#39;labels&#39;, &#39;softlabels&#39;] simclr_df.columns = [&#39;image_id&#39;, &#39;labels&#39;, &#39;softlabels&#39;] . from sklearn.model_selection import StratifiedKFold import gc N_FOLDS = 3 rotnet_df[&#39;fold&#39;] = -1 strat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=42, shuffle=True) for i, (_, test_index) in enumerate(strat_kfold.split(rotnet_df.image_id.values, rotnet_df[&#39;labels&#39;].values)): rotnet_df.iloc[test_index, -1] = i rotnet_df[&#39;fold&#39;] = rotnet_df[&#39;fold&#39;].astype(&#39;int&#39;) . N_FOLDS = 3 simclr_df[&#39;fold&#39;] = -1 strat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=42, shuffle=True) for i, (_, test_index) in enumerate(strat_kfold.split(simclr_df.image_id.values, simclr_df[&#39;labels&#39;].values)): simclr_df.iloc[test_index, -1] = i simclr_df[&#39;fold&#39;] = simclr_df[&#39;fold&#39;].astype(&#39;int&#39;) . class SoftLabelCB(Callback): def __init__(self, df_preds, y_true_weight = 0.5): &#39;&#39;&#39;df_preds is a pandas dataframe where index is image paths Must have y_true and y_pred one hot encoded columns (ie y_true_0, y_true_1) &#39;&#39;&#39; self.y_true_weight = y_true_weight self.y_pred_weight = 1 - y_true_weight self.df = pd.get_dummies(df_preds, columns=[&#39;labels&#39;, &#39;softlabels&#39;]) def before_train(self): if type(self.dl.items)==type(pd.DataFrame()): self.idx_list = L(o for o in self.dl.items.index.values) if is_listy(self.dl.items): self.imgs_list = L(self.dl.items) def before_validate(self): if type(self.dl.items)==type(pd.DataFrame()): self.idx_list = L(o for o in self.dl.items.index.values) if is_listy(self.dl.items): self.imgs_list = L(self.dl.items) def before_batch(self): # get the images&#39; names for the current batch idx = self.idx_list[self.dl._DataLoader__idxs[self.iter*self.dl.bs:self.iter*self.dl.bs+self.dl.bs]] # get soft labels df = self.df soft_labels = df.loc[idx,df.columns.str.startswith(&#39;labels&#39;)].values if self.training: soft_labels = soft_labels*self.y_true_weight + df.loc[idx,df.columns.str.startswith(&#39;softlabels&#39;)].values*self.y_pred_weight self.learn.yb = (Tensor(soft_labels).cuda(),) class CrossEntropyLossOneHot(nn.Module): def __init__(self): super(CrossEntropyLossOneHot, self).__init__() self.log_softmax = nn.LogSoftmax(dim=-1) def forward(self, preds, labels): return torch.mean(torch.sum(-labels * self.log_softmax(preds), -1)) def accuracy(inp, targ, axis=-1): &quot;Compute accuracy with `targ` when `pred` is bs * n_classes&quot; pred,targ = flatten_check(inp.argmax(dim=axis), targ.argmax(dim=axis)) return (pred == targ).float().mean() . for i in range(N_FOLDS): gc.collect() dls = get_dls(rotnet_df, 228, i, bs=32) model = get_model(rotnet_df, True) sm = SaveModelCallback(monitor=&#39;valid_loss&#39;, fname=f&#39;{path}/model/rotnet_downstm_fold_{i}_best&#39;) learn = Learner(dls, model, loss_func=CrossEntropyLossOneHot(), metrics=[accuracy, RocAuc()], cbs=[SoftLabelCB(rotnet_df)]) learn.fine_tune(25, base_lr=1e-3, reset_opt=True, cbs=sm, freeze_epochs=2) . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 2.180979 | 1.798362 | 0.400330 | 0.617794 | 06:34 | . 1 | 1.896754 | 1.784741 | 0.444811 | 0.667562 | 01:35 | . Better model found at epoch 0 with valid_loss value: 1.798362374305725. Better model found at epoch 1 with valid_loss value: 1.7847411632537842. . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 1.484100 | 1.153402 | 0.556837 | 0.730138 | 01:35 | . 1 | 1.320654 | 1.144631 | 0.570017 | 0.770639 | 01:34 | . 2 | 1.314283 | 1.177314 | 0.561779 | 0.756559 | 01:35 | . 3 | 1.311820 | 1.222077 | 0.563427 | 0.743319 | 01:35 | . 4 | 1.308478 | 1.284149 | 0.558484 | 0.765968 | 01:35 | . 5 | 1.241711 | 1.096887 | 0.596376 | 0.773927 | 01:35 | . 6 | 1.205534 | 1.040225 | 0.611203 | 0.790580 | 01:33 | . 7 | 1.109477 | 1.162204 | 0.619440 | 0.773357 | 01:35 | . 8 | 1.038942 | 0.975802 | 0.647446 | 0.827652 | 01:35 | . 9 | 0.926236 | 0.790048 | 0.728171 | 0.870287 | 01:35 | . 10 | 0.850851 | 0.666998 | 0.757825 | 0.879508 | 01:35 | . 11 | 0.766376 | 0.633047 | 0.775947 | 0.898495 | 01:35 | . 12 | 0.690296 | 0.546291 | 0.785832 | 0.924340 | 01:35 | . 13 | 0.646431 | 0.558037 | 0.790774 | 0.916405 | 01:36 | . 14 | 0.617734 | 0.487432 | 0.823723 | 0.928350 | 01:35 | . 15 | 0.578832 | 0.504875 | 0.827018 | 0.922318 | 01:34 | . 16 | 0.555530 | 0.594202 | 0.812191 | 0.901316 | 01:35 | . 17 | 0.524157 | 0.443095 | 0.836903 | 0.941674 | 01:35 | . 18 | 0.490369 | 0.416304 | 0.851730 | 0.942821 | 01:35 | . 19 | 0.476614 | 0.419605 | 0.855025 | 0.944162 | 01:36 | . 20 | 0.453619 | 0.403086 | 0.850082 | 0.946465 | 01:35 | . 21 | 0.438267 | 0.398012 | 0.863262 | 0.945645 | 01:36 | . 22 | 0.421713 | 0.392551 | 0.858320 | 0.947091 | 01:36 | . 23 | 0.406884 | 0.391196 | 0.858320 | 0.947049 | 01:36 | . 24 | 0.416799 | 0.393447 | 0.855025 | 0.948277 | 01:34 | . Better model found at epoch 0 with valid_loss value: 1.1534024477005005. Better model found at epoch 1 with valid_loss value: 1.1446309089660645. Better model found at epoch 5 with valid_loss value: 1.096887469291687. Better model found at epoch 6 with valid_loss value: 1.0402253866195679. Better model found at epoch 8 with valid_loss value: 0.9758020043373108. Better model found at epoch 9 with valid_loss value: 0.7900478839874268. Better model found at epoch 10 with valid_loss value: 0.6669976115226746. Better model found at epoch 11 with valid_loss value: 0.6330470442771912. Better model found at epoch 12 with valid_loss value: 0.546291172504425. Better model found at epoch 14 with valid_loss value: 0.48743197321891785. Better model found at epoch 17 with valid_loss value: 0.4430951774120331. Better model found at epoch 18 with valid_loss value: 0.41630420088768005. Better model found at epoch 20 with valid_loss value: 0.40308573842048645. Better model found at epoch 21 with valid_loss value: 0.3980117738246918. Better model found at epoch 22 with valid_loss value: 0.392551451921463. Better model found at epoch 23 with valid_loss value: 0.39119648933410645. . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 2.077682 | 1.358871 | 0.421746 | 0.630542 | 01:35 | . 1 | 1.890515 | 1.920299 | 0.433278 | 0.624589 | 01:35 | . Better model found at epoch 0 with valid_loss value: 1.3588707447052002. . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 1.721737 | 1.420372 | 0.471170 | 0.660035 | 01:34 | . 1 | 1.556469 | 1.232172 | 0.560132 | 0.708895 | 01:35 | . 2 | 1.505628 | 1.309458 | 0.560132 | 0.715855 | 01:35 | . 3 | 1.521256 | 1.261295 | 0.537068 | 0.709441 | 01:35 | . 4 | 1.445887 | 1.404649 | 0.542010 | 0.675589 | 01:35 | . 5 | 1.421579 | 1.613186 | 0.505766 | 0.688969 | 01:35 | . 6 | 1.341298 | 1.260396 | 0.542010 | 0.698050 | 01:34 | . 7 | 1.266212 | 1.263892 | 0.599671 | 0.739613 | 01:35 | . 8 | 1.192686 | 1.052656 | 0.624382 | 0.782726 | 01:35 | . 9 | 1.123260 | 0.921180 | 0.640857 | 0.814421 | 01:35 | . 10 | 1.071517 | 0.980215 | 0.649094 | 0.796601 | 01:35 | . 11 | 1.003980 | 0.835629 | 0.698517 | 0.825559 | 01:35 | . 12 | 0.914666 | 1.014547 | 0.685338 | 0.805289 | 01:35 | . 13 | 0.815322 | 0.875604 | 0.696870 | 0.832545 | 01:35 | . 14 | 0.755339 | 0.692518 | 0.754530 | 0.861947 | 01:35 | . 15 | 0.682022 | 0.717943 | 0.764415 | 0.860634 | 01:35 | . 16 | 0.627511 | 0.689097 | 0.752883 | 0.853841 | 01:35 | . 17 | 0.552456 | 0.604317 | 0.797364 | 0.871979 | 01:36 | . 18 | 0.551212 | 0.627598 | 0.803954 | 0.880846 | 01:35 | . 19 | 0.544026 | 0.636285 | 0.803954 | 0.873143 | 01:35 | . 20 | 0.505864 | 0.585278 | 0.808896 | 0.886988 | 01:35 | . 21 | 0.483512 | 0.540007 | 0.828666 | 0.894359 | 01:35 | . 22 | 0.474091 | 0.579923 | 0.820428 | 0.883195 | 01:35 | . 23 | 0.456476 | 0.580129 | 0.825371 | 0.882503 | 01:35 | . 24 | 0.450166 | 0.562739 | 0.827018 | 0.885534 | 01:35 | . Better model found at epoch 0 with valid_loss value: 1.4203722476959229. Better model found at epoch 1 with valid_loss value: 1.232171893119812. Better model found at epoch 8 with valid_loss value: 1.052655577659607. Better model found at epoch 9 with valid_loss value: 0.9211796522140503. Better model found at epoch 11 with valid_loss value: 0.8356290459632874. Better model found at epoch 14 with valid_loss value: 0.6925175189971924. Better model found at epoch 16 with valid_loss value: 0.6890971064567566. Better model found at epoch 17 with valid_loss value: 0.6043166518211365. Better model found at epoch 20 with valid_loss value: 0.5852775573730469. Better model found at epoch 21 with valid_loss value: 0.5400067567825317. . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 2.081328 | 1.790862 | 0.342669 | 0.594329 | 01:33 | . 1 | 1.812289 | 1.978368 | 0.461285 | 0.698615 | 01:35 | . Better model found at epoch 0 with valid_loss value: 1.7908616065979004. . epoch train_loss valid_loss accuracy roc_auc_score time . 0 | 1.681780 | 1.351755 | 0.423394 | 0.678330 | 01:35 | . 1 | 1.628255 | 1.253813 | 0.533773 | 0.726907 | 01:35 | . 2 | 1.514754 | 1.179286 | 0.543657 | 0.744522 | 01:35 | . 3 | 1.446746 | 1.149792 | 0.537068 | 0.747809 | 01:35 | . 4 | 1.452345 | 1.244986 | 0.546952 | 0.685498 | 01:35 | . 5 | 1.401141 | 1.286189 | 0.560132 | 0.746649 | 01:35 | . 6 | 1.342116 | 1.166848 | 0.556837 | 0.741916 | 01:35 | . 7 | 1.276286 | 1.104091 | 0.593081 | 0.772318 | 01:33 | . 8 | 1.199893 | 1.050359 | 0.614498 | 0.784405 | 01:35 | . 9 | 1.111698 | 0.914566 | 0.640857 | 0.823923 | 01:35 | . 10 | 1.059557 | 0.892816 | 0.665568 | 0.839800 | 01:35 | . 11 | 0.988732 | 0.863787 | 0.688633 | 0.842417 | 01:35 | . 12 | 0.886488 | 0.689515 | 0.746293 | 0.871834 | 01:35 | . 13 | 0.803669 | 0.739485 | 0.744646 | 0.869706 | 01:35 | . 14 | 0.719890 | 0.716404 | 0.757825 | 0.902299 | 01:35 | . 15 | 0.649968 | 0.674304 | 0.775947 | 0.899190 | 01:34 | . 16 | 0.613759 | 0.650748 | 0.761120 | 0.902635 | 01:33 | . 17 | 0.573795 | 0.488263 | 0.835255 | 0.932428 | 01:35 | . 18 | 0.549245 | 0.499743 | 0.831960 | 0.928918 | 01:35 | . 19 | 0.518839 | 0.460697 | 0.835255 | 0.935363 | 01:35 | . 20 | 0.480734 | 0.425933 | 0.851730 | 0.945728 | 01:35 | . 21 | 0.465403 | 0.426006 | 0.855025 | 0.945700 | 01:35 | . 22 | 0.442722 | 0.419363 | 0.853377 | 0.947554 | 01:35 | . 23 | 0.466067 | 0.409462 | 0.861615 | 0.949312 | 01:35 | . 24 | 0.467920 | 0.411176 | 0.866557 | 0.949608 | 01:35 | . Better model found at epoch 0 with valid_loss value: 1.3517550230026245. Better model found at epoch 1 with valid_loss value: 1.2538130283355713. Better model found at epoch 2 with valid_loss value: 1.1792856454849243. Better model found at epoch 3 with valid_loss value: 1.1497923135757446. Better model found at epoch 7 with valid_loss value: 1.104090929031372. Better model found at epoch 8 with valid_loss value: 1.0503588914871216. Better model found at epoch 9 with valid_loss value: 0.9145664572715759. Better model found at epoch 10 with valid_loss value: 0.8928159475326538. Better model found at epoch 11 with valid_loss value: 0.8637869358062744. Better model found at epoch 12 with valid_loss value: 0.6895149350166321. Better model found at epoch 15 with valid_loss value: 0.6743040680885315. Better model found at epoch 16 with valid_loss value: 0.650747537612915. Better model found at epoch 17 with valid_loss value: 0.48826295137405396. Better model found at epoch 19 with valid_loss value: 0.4606971740722656. Better model found at epoch 20 with valid_loss value: 0.4259330928325653. Better model found at epoch 22 with valid_loss value: 0.419363409280777. Better model found at epoch 23 with valid_loss value: 0.4094623327255249. . Those are pretty amazing results! . References: . https://amarsaini.github.io/Epoching-Blog/jupyter/2020/03/23/Self-Supervision-with-FastAI.html . https://github.com/Isaac-Flath/fastblog/blob/master/_notebooks/2021-02-15-PlantPathology.ipynb . https://keremturgutlu.github.io/self_supervised/ . https://www.kaggle.com/keremt/progressive-label-correction-paper-implementation . https://paperswithcode.com/method/simclr . https://medium.com/wicds/exploring-the-essence-of-simclr-8e205ebc77af . https://www.pyimagesearch.com/2021/01/18/contrastive-loss-for-siamese-networks-with-keras-and-tensorflow/ .",
            "url": "https://moarshy.github.io/blogs/image%20classification/fastai/self-supervised/soft-label/2021/03/31/sslsoftlabeling.html",
            "relUrl": "/image%20classification/fastai/self-supervised/soft-label/2021/03/31/sslsoftlabeling.html",
            "date": " • Mar 31, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Continuing with DICOM",
            "content": "In this blog, we will largely use Jeremy Howard&#39;s series of notebooks on Kaggle to understand DICOM and to learn how to use fastai.medical to work with DICOM files. I would highly encourage going through Jeremy&#39;s blogs. Here, I will be merely be blogging as I learn and practice his notebooks. . There are five notebooks in this series. In this blog, we will go through the first four notebooks. . Creating a metadata DataFrame - In this notebook, we will learn how to create a DataFrame from DICOM metadata . | Some DICOM gotchas to be aware of - Here, we will learn some things to watch out for when working with DICOM like signed data being used as if it were unsigned . | Don&#39;t see like a radiologist - Radiologists, as we will learn below, use windowing to observe different area of interest such as brain, subdural because humans are limited in their ability to distinguish different contrast levels. This human limitations does not affect macines. In this notebook, we will learn how we can prepare (normalize) our images to help our model learn better. . | Cleaning the data for rapid prototyping - We will put our learnings into action by preparing a prototyping dataset. We will clean the data and then make a smaller set of smaller JPEG images for prototyping. . | From prototyping to submission - In this final notebook, we will learn to use our prototype dataset in building a classifier then learn to use full scale dataset to train our classifier. not covered in this blog . | Importing . from fastai.basics import * from fastai.vision.all import * from fastai.medical.imaging import * import seaborn as sns . Creating a metadata dataframe . The first notebook show us how to make a dataframe from dcm files. . path_dest = Path(&#39;./&#39;) . path = Path(&#39;../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection&#39;) . path_trn = path/&#39;stage_2_train&#39; fns_trn = path_trn.ls() . path_tst = path/&#39;stage_2_test&#39; fns_tst = path_tst.ls() . fn = fns_trn[0] dcm = fn.dcmread() dcm . Dataset.file_meta - (0002, 0002) Media Storage SOP Class UID UI: CT Image Storage (0002, 0003) Media Storage SOP Instance UID UI: 10000000300633 (0002, 0010) Transfer Syntax UID UI: Implicit VR Little Endian (0002, 0012) Implementation Class UID UI: 1.2.3.4 (0002, 0013) Implementation Version Name SH: &#39;RSNA Challenge 2019&#39; - (0008, 0018) SOP Instance UID UI: ID_27a354d42 (0008, 0060) Modality CS: &#39;CT&#39; (0010, 0020) Patient ID LO: &#39;ID_907f00d7&#39; (0020, 000d) Study Instance UID UI: ID_f69dbbd67a (0020, 000e) Series Instance UID UI: ID_8408ebcd9f (0020, 0010) Study ID SH: &#39;&#39; (0020, 0032) Image Position (Patient) DS: [-125, -18, 111.900024] (0020, 0037) Image Orientation (Patient) DS: [1, 0, 0, 0, 1, 0] (0028, 0002) Samples per Pixel US: 1 (0028, 0004) Photometric Interpretation CS: &#39;MONOCHROME2&#39; (0028, 0010) Rows US: 512 (0028, 0011) Columns US: 512 (0028, 0030) Pixel Spacing DS: [0.48828125, 0.48828125] (0028, 0100) Bits Allocated US: 16 (0028, 0101) Bits Stored US: 12 (0028, 0102) High Bit US: 11 (0028, 0103) Pixel Representation US: 0 (0028, 1050) Window Center DS: [00036, 00036] (0028, 1051) Window Width DS: [00080, 00080] (0028, 1052) Rescale Intercept DS: &#34;-1024.0&#34; (0028, 1053) Rescale Slope DS: &#34;1.0&#34; (7fe0, 0010) Pixel Data OW: Array of 524288 elements . Looking at an example dcm file we can see that we have seen and cover most of the data elements in our previous blog except Window Center, Window Width, Rescale Intercept and Rescale Slope. We will focus on them. . (0028, 1050) Window Center and (0028, 1051) Window Width The grayscale values of a CT is made up of a range of pixel values. Since they are either 12-bit or 16-bit, the range of possible values are 0-4096 (for 12-bit) and 0-65536 (for 16-bit). This is in comparison to a normal 8-bit images whose values range between 0-255. The larger the range, larger is the levels of contrast. Our human eyes are merely good at contrasting 100 levels of contrast. A 12-bit image would therefore provide 4096 contrast levels which could be difficult for humans to differentiate. Hence, in CTs, it is normal to choose a range of value to observe. The midlevel of the range is the Window Center and the range is Window Level. We can also think of varying Window Center as varying the brighness and varying the Window Level as varying the contrast. . fastai provides the Window Level and Window Center for observing different area of interest. Let&#39;s take a look at few . dicom_windows . namespace(brain=(80, 40), subdural=(254, 100), stroke=(8, 32), brain_bone=(2800, 600), brain_soft=(375, 40), lungs=(1500, -600), mediastinum=(350, 50), abdomen_soft=(400, 50), liver=(150, 30), spine_soft=(250, 50), spine_bone=(1800, 400)) . dicom_windows.brain . (80, 40) . dicom_windows.subdural . (254, 100) . Let&#39;s use fastai functionality to see some of these images under different windowing. . Note: We will learn about normalized windowing later in the blog . scales = False, True, dicom_windows.brain, dicom_windows.subdural titles = &#39;raw&#39;,&#39;normalized&#39;,&#39;brain windowed&#39;,&#39;subdural windowed&#39; for s,a,t in zip(scales, subplots(2,2,imsize=5)[1].flat, titles): dcm.show(scale=s, ax=a, title=t) . Rescale Intercept and Rescale Slope Now, let&#39;s move to understanding Rescale Intercept and Rescale Slope. The concept is pretty simple. DICOM uses linear transformation to save pixel values when stored on disk and when it is moved to memory. . y = mx + c . m is the Rescale Slope and c is the Rescale Intercept. . Why is this linear transformation needed? CT scans are meaured in Hounsfield Units which can be negative and they are stored as unsigned integers format which goes from 0 and above. Hence, a linear transformation is needed to shift the range of values. . Now that we have understood some of the important data elements. Let&#39;s prepare the dataframes so it would be easier to work with. fastai/pydicom provides really easy way to convert DICOM to dataframe. . . Note: Preparing these dataframes from DICOM takes really long. When I ran it on Kaggle, it took about 8 hours to make df_trn and df_tst below. . def save_lbls(): path_lbls = path/&#39;stage_2_train.csv&#39; lbls = pd.read_csv(path_lbls) lbls[[&quot;ID&quot;,&quot;htype&quot;]] = lbls.ID.str.rsplit(&quot;_&quot;, n=1, expand=True) lbls.drop_duplicates([&#39;ID&#39;,&#39;htype&#39;], inplace=True) pvt = lbls.pivot(&#39;ID&#39;, &#39;htype&#39;, &#39;Label&#39;) pvt.reset_index(inplace=True) pvt.to_feather(&#39;labels.fth&#39;) . . #df_lbls.head(8) . . #df_tst.to_feather(&#39;df_tst.fth&#39;) #df_tst.head() . #df_trn.to_feather(&#39;df_trn.fth&#39;) . Some DICOM gotchas to be aware of . From here, we will work on Jeremy&#39;s &quot;Some DICOM gotchas to be aware of&quot;. . path_df = Path(&#39;../input/dataframes&#39;) path_df.ls() . (#3) [Path(&#39;../input/dataframes/df_tst.fth&#39;),Path(&#39;../input/dataframes/labels.fth&#39;),Path(&#39;../input/dataframes/df_trn.fth&#39;)] . df_lbls = pd.read_feather(path_df/&#39;labels.fth&#39;) df_tst = pd.read_feather(path_df/&#39;df_tst.fth&#39;) df_trn = pd.read_feather(path_df/&#39;df_trn.fth&#39;) . We merge the df_lbls dataframe with df_trn. . comb = df_trn.join(df_lbls.set_index(&#39;ID&#39;), &#39;SOPInstanceUID&#39;) assert not len(comb[comb[&#39;any&#39;].isna()]) . comb.head(10) . SOPInstanceUID Modality PatientID StudyInstanceUID SeriesInstanceUID StudyID ImagePositionPatient ImageOrientationPatient SamplesPerPixel PhotometricInterpretation ... img_max img_mean img_std img_pct_window any epidural intraparenchymal intraventricular subarachnoid subdural . 0 ID_27a354d42 | CT | ID_907f00d7 | ID_f69dbbd67a | ID_8408ebcd9f | | -125.000000 | 1.0 | 1 | MONOCHROME2 | ... | 2671 | 454.914642 | 616.514427 | 0.149364 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 ID_9ef779a18 | CT | ID_8bca9b69 | ID_ed4776c4b6 | ID_073c18243c | | -125.000000 | 1.0 | 1 | MONOCHROME2 | ... | 2778 | -330.188461 | 1415.697408 | 0.266693 | 1 | 0 | 1 | 0 | 1 | 1 | . 2 ID_5bed38bf6 | CT | ID_b501522f | ID_906af9ca62 | ID_719a4e6a78 | | -125.000000 | 1.0 | 1 | MONOCHROME2 | ... | 2687 | -128.333286 | 678.065725 | 0.004173 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 ID_286599272 | CT | ID_7ba59d14 | ID_9f39f65610 | ID_b55ce168f2 | | -137.500000 | 1.0 | 1 | MONOCHROME2 | ... | 2568 | 396.514767 | 528.022874 | 0.107368 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 ID_bba76cea8 | CT | ID_32c07778 | ID_f9641021e5 | ID_e04ed2ad5c | | -122.000000 | 1.0 | 1 | MONOCHROME2 | ... | 2413 | 521.192650 | 568.400446 | 0.263206 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 ID_a917377cd | CT | ID_e4488e09 | ID_f13c83c8ae | ID_91366e3a6e | | -107.800003 | 1.0 | 1 | MONOCHROME2 | ... | 2756 | -90.590172 | 1140.209042 | 0.115768 | 0 | 0 | 0 | 0 | 0 | 0 | . 6 ID_7723b03a6 | CT | ID_a329da04 | ID_cd9053516e | ID_37b71d633c | | -125.000000 | 1.0 | 1 | MONOCHROME2 | ... | 2732 | -308.353733 | 949.515538 | 0.008362 | 0 | 0 | 0 | 0 | 0 | 0 | . 7 ID_dbb1cc814 | CT | ID_afd8ebfe | ID_55af39ec1b | ID_eb25c44049 | | -107.000000 | 1.0 | 1 | MONOCHROME2 | ... | 2374 | 448.588409 | 488.864187 | 0.126221 | 0 | 0 | 0 | 0 | 0 | 0 | . 8 ID_4b08fe185 | CT | ID_6338c4f1 | ID_a3b607ba3f | ID_468e9dedde | | -125.000000 | 1.0 | 1 | MONOCHROME2 | ... | 3082 | 66.582775 | 1203.552054 | 0.235271 | 0 | 0 | 0 | 0 | 0 | 0 | . 9 ID_8192d735e | CT | ID_b4a5aa19 | ID_3f35938aea | ID_1ff3a48327 | | -132.000000 | 1.0 | 1 | MONOCHROME2 | ... | 2612 | 471.477554 | 578.011862 | 0.277931 | 0 | 0 | 0 | 0 | 0 | 0 | . 10 rows × 48 columns . Looking at BitsStored and PixelRepresentation . Recap . BitsStored - Tells whether the data is stored in 12 or 16 bits . PixelRepresentation - Tells if the data it is signed or unsigned data. Signed data can have negative pixels while unsigned starts from 0 and above. . repr_flds = [&#39;BitsStored&#39;,&#39;PixelRepresentation&#39;] comb.pivot_table(values=[&#39;img_mean&#39;,&#39;img_max&#39;,&#39;img_min&#39;,&#39;PatientID&#39;,&#39;any&#39;], index=repr_flds, aggfunc={&#39;img_mean&#39;:&#39;mean&#39;,&#39;img_max&#39;:&#39;max&#39;,&#39;img_min&#39;:&#39;min&#39;,&#39;PatientID&#39;:&#39;count&#39;,&#39;any&#39;:&#39;mean&#39;}) . PatientID any img_max img_mean img_min . BitsStored PixelRepresentation . 12 0 333443 | 0.128409 | 4095 | 451.058719 | 0 | . 1 2312 | 0.335640 | 2047 | -639.495079 | -2048 | . 16 1 417048 | 0.154275 | 32767 | 41.121570 | -32768 | . We can see that that when PixelRepresentation is 1, meaning the data type is signed, img_min can take negative values. Largely, we will be working with unsigned 12-bit data and signed 16-bit data. . As we saw earlier RescaleIntercept and RescaleSlope tell us how to scale our data. Let&#39;s take a look. . comb.pivot_table(values=[&#39;WindowCenter&#39;,&#39;WindowWidth&#39;, &#39;RescaleIntercept&#39;, &#39;RescaleSlope&#39;], index=repr_flds, aggfunc={&#39;mean&#39;,&#39;max&#39;,&#39;min&#39;,&#39;std&#39;,&#39;median&#39;}) . RescaleIntercept RescaleSlope WindowCenter WindowWidth . max mean median min std max mean median min std max mean median min std max mean median min std . BitsStored PixelRepresentation . 12 0 1.0 | -1023.141245 | -1024.0 | -1024.0 | 19.947663 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 650.0 | 37.940949 | 36.0 | 25.0 | 19.130654 | 4095.0 | 85.132092 | 80.0 | 26.0 | 127.766167 | . 1 0.0 | 0.000000 | 0.0 | 0.0 | 0.000000 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 350.0 | 48.775952 | 40.0 | 40.0 | 47.549496 | 4000.0 | 179.653979 | 80.0 | 80.0 | 603.265211 | . 16 1 0.0 | -1016.754254 | -1024.0 | -1024.0 | 85.832168 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 800.0 | 33.426668 | 30.0 | 25.0 | 19.091547 | 3000.0 | 100.568292 | 80.0 | 60.0 | 95.569248 | . Firstly, we know that CT scans are measured in Hounsfield Units (HU) which takes both negative and positive values. HU measures the radiodensity (how much radiation is absorbed) by differnt materials such as air, fats, bones. Some radiodensity values of different materials are Air -100 HU; Fat -120 to -90 HU; Bone (Cortical) +500 to +1900 . Based on this, we expect the mean RescaleIntercept for PixelRepresentation 0 to be around -1,024 but in our case there seem to be some with RescaleIntercept not equlas to -1,024. . The issue here could be that some of the images were signed data but were treated as unsigned. Later we will look at how to deal with them. . Now, lets take a look scaled_px function that fastai provides to easliy scale pixels based on their RescaleIntercept and RescaleSlope . dcm = path_trn.ls(1)[0].dcmread() . dcm.pixels . tensor([[24., 22., 22., ..., 21., 17., 17.], [25., 25., 23., ..., 21., 20., 18.], [26., 27., 25., ..., 21., 20., 21.], ..., [17., 18., 19., ..., 19., 19., 20.], [23., 22., 21., ..., 20., 21., 21.], [22., 21., 20., ..., 20., 20., 20.]]) . plt.hist(dcm.pixels.flatten().numpy()); . dcm.scaled_px . tensor([[-1000., -1002., -1002., ..., -1003., -1007., -1007.], [ -999., -999., -1001., ..., -1003., -1004., -1006.], [ -998., -997., -999., ..., -1003., -1004., -1003.], ..., [-1007., -1006., -1005., ..., -1005., -1005., -1004.], [-1001., -1002., -1003., ..., -1004., -1003., -1003.], [-1002., -1003., -1004., ..., -1004., -1004., -1004.]]) . plt.hist(dcm.scaled_px.flatten().numpy()); . DON&#39;T see like a radiologist! . Next, we will work on Jeremy&#39;s &quot;DON&#39;T see like a radiologist!&quot; notebook. . In this notebook, Jeremy&#39;s presents an idea as to how to help our model see better. We have seen earlier windowing is used to help radiologists to vary contrast and brightness to observe difffernt areas of interests such as the brain and the subdural. The reason for windowing is humans are only able to contrast about 100 levels of contrast gradient but a 16-bit CT has 2^16 (65,536) levels of contrast gradient. This is beyond a human&#39;s ability to distinguish hence windowning is used but this is not a problem for computer. . Let&#39;s see an image without windowing vs brain_window. . fname = path_trn.ls(10)[0] _, axes = plt.subplots(1, 2, figsize=(10,8)) dcm = fname.dcmread() for ax, name, window in zip(axes.flat, [&#39;no windowing&#39;, &#39;brain wondow&#39;], [None, dicom_windows.brain]): dcm.show(scale=window, ctx=ax, title=name) . This limitations of number of contrast gradient is not at all an issue for computer but we do have to rescale to help our models. Let&#39;s take a look at Jeremy&#39;s proposal. Let&#39;s see the rescaling. . px = dcm.scaled_px.flatten() sns.histplot(px) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . We see a highly bimodal distribution. Background pixels are around -1000, and the brain tissue pixels are around 0. The proposal is to use non-linear mapping designed to give us an equal number of pixels in each range. Let&#39;s see how that is done. . bins = px.freqhist_bins(20) sns.histplot(dcm.scaled_px.flatten(), bins=bins) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . &#39;fastai.medical.imaging&#39; can apply that non-linear mapping for you. In fact, this is the default way of displaying a DICOM in fastai. This is the normalized windowing we saw earlier. . plt.imshow(dcm.hist_scaled(), cmap=plt.cm.bone); . dcm.show() . Creating a normalised dataset . Now that we know how to scale our dcm, let&#39;s take a look at preparing our dataset. Because the non-linear mapping we used varies from image to image, we will need to create a mapping that is appropriate for a wide range of images. . We will create a mapping for three different groups of images we saw earlier. . df1 = comb.query(&#39;(BitsStored==12) &amp; (PixelRepresentation==0)&#39;) df2 = comb.query(&#39;(BitsStored==12) &amp; (PixelRepresentation==1)&#39;) df3 = comb.query(&#39;BitsStored==16&#39;) dfs = L(df1,df2,df3) . To create the bins . we will grab a random image with each label (htypes) and one with no labels for all the three groups above | then we will read the dcm | put them into a tensor | get the bins from this set of images | use the bins in hist_scaled_px to get the scaled float tensor, which we can pass to our model | htypes = &#39;any&#39;,&#39;epidural&#39;,&#39;intraparenchymal&#39;,&#39;intraventricular&#39;,&#39;subarachnoid&#39;,&#39;subdural&#39; def get_samples(df): recs = [df.query(f&#39;{c}==1&#39;).sample() for c in htypes] recs.append(df.query(&#39;any==0&#39;).sample()) return pd.concat(recs).fname.values sample_fns = concat(*dfs.map(get_samples)) . sample_dcms = L(Path(o).dcmread() for o in sample_fns) samples = torch.stack(tuple(sample_dcms.attrgot(&#39;scaled_px&#39;))) samples.shape . torch.Size([21, 512, 512]) . bins = samples.freqhist_bins() plt.plot(bins, torch.linspace(0,1,len(bins))); . dcm.show(bins) . dcm.hist_scaled(bins), dcm.hist_scaled(bins).shape . (tensor([[0.1558, 0.1299, 0.1299, ..., 0.1169, 0.0649, 0.0649], [0.1688, 0.1688, 0.1429, ..., 0.1169, 0.1039, 0.0779], [0.1818, 0.1948, 0.1688, ..., 0.1169, 0.1039, 0.1169], ..., [0.0649, 0.0779, 0.0909, ..., 0.0909, 0.0909, 0.1039], [0.1429, 0.1299, 0.1169, ..., 0.1039, 0.1169, 0.1169], [0.1299, 0.1169, 0.1039, ..., 0.1039, 0.1039, 0.1039]]), torch.Size([512, 512])) . Since the non-linear mapping results in a almost uniform distribution between 0 and 1, we wont have a mean and std of 0 and 1. . scaled_samples = torch.stack(tuple(o.hist_scaled(bins) for o in sample_dcms)) scaled_samples.mean(),scaled_samples.std() . (tensor(0.4080), tensor(0.2989)) . Cleaning the data for rapid prototyping . In this notebook, we learn . how to fix images with incorrect RescaleIntercept | removing images with minimal useful information | make a smaller dataset that we can use for prototyping | crop images to just contain the brain area | carry out histogram rescaling and save it as JPEG | The idea, apart from fixing incorrect images, is to create a dataset for rapid prototyping. . Fixing incorrect RescaleIntercept . The problematic images were found in our df1. . df1 = comb.query(&#39;(BitsStored==12) &amp; (PixelRepresentation==0)&#39;) . def df2dcm(df): return L(Path(o).dcmread() for o in df.fname.values) . df_iffy = df1[df1.RescaleIntercept&gt;-100] dcms = df2dcm(df_iffy) _,axs = subplots(2,4, imsize=3) for i,ax in enumerate(axs.flat): dcms[i].show(ax=ax) . That does not look good at all. . dcm = dcms[2] d = dcm.pixel_array plt.hist(d.flatten()); . As explained previously, the mode for unsigned data appears around 0 but in our case the mode appears around 3000. This could be because signed data could have been treated as if it were unsigned data. As explained by Jeremy . My guess is that what happened in the &quot;iffy&quot; images is that they were actually signed data, &gt;but were treated as unsigned. If that&#39;s the case, the a value of -1000 or -1024 (the usual &gt;values for background pixels in signed data images) will have wrapped around to 4096-&gt;1000=3096. So we&#39;ll need to shift everything up by 1000, then move the values larger than &gt;2048 back to where they should have been. . The fix is . add all pixel values by +1000 | for values more than 4096, -1000 | set RescaleIntercept to -1000 | d += 1000 px_mode = scipy.stats.mode(d.flatten()).mode[0] d[d&gt;=px_mode] = d[d&gt;=px_mode] - px_mode dcm.PixelData = d.tobytes() dcm.RescaleIntercept = -1000 . plt.hist(dcm.pixel_array.flatten()); . _,axs = subplots(1,2) dcm.show(ax=axs[0]); dcm.show(dicom_windows.brain, ax=axs[1]) . def fix_pxrepr(dcm): if dcm.PixelRepresentation != 0 or dcm.RescaleIntercept&lt;-100: return x = dcm.pixel_array + 1000 px_mode = 4096 x[x&gt;=px_mode] = x[x&gt;=px_mode] - px_mode dcm.PixelData = x.tobytes() dcm.RescaleIntercept = -1000 . dcms = df2dcm(df_iffy) dcms.map(fix_pxrepr) _,axs = subplots(2,4, imsize=3) for i,ax in enumerate(axs.flat): dcms[i].show(ax=ax) . Images look better following our repair work . Remove useless images . To remove &#39;not so useful&#39; images we will identify what % of pixel of an images is in the brain window (0, 80). This is already in the dataframe we created earlier under img_pct_window. . plt.hist(comb.img_pct_window,40); . comb = comb.assign(pct_cut = pd.cut(comb.img_pct_window, [0,0.02,0.05,0.1,0.2,0.3,1])) comb.pivot_table(values=&#39;any&#39;, index=&#39;pct_cut&#39;, aggfunc=[&#39;sum&#39;,&#39;count&#39;]).T . pct_cut (0.0, 0.02] (0.02, 0.05] (0.05, 0.1] (0.1, 0.2] (0.2, 0.3] (0.3, 1.0] . sum any 69 | 775 | 3690 | 23411 | 61741 | 18246 | . count any 79144 | 22217 | 50928 | 269727 | 255338 | 67315 | . We can see that images with little brain tissue (&lt;2% of pixels) have almost no labels. So we will remove them. . comb.drop(comb.query(&#39;img_pct_window&lt;0.02&#39;).index, inplace=True) . Resample to 2/3 split . df_lbl = comb.query(&#39;any==True&#39;) n_lbl = len(df_lbl) n_lbl . 107863 . df_nonlbl = comb.query(&#39;any==False&#39;).sample(n_lbl//2) len(df_nonlbl) . 53931 . comb = pd.concat([df_lbl,df_nonlbl]) len(comb) . 161794 . Crop to just brain area&#182; . dcm = Path(dcms[10].filename).dcmread() fix_pxrepr(dcm) . px = dcm.windowed(*dicom_windows.brain) show_image(px); . blurred = gauss_blur2d(px, 100) show_image(blurred); . show_image(blurred&gt;0.3); . _,axs = subplots(1,4, imsize=3) for i,ax in enumerate(axs.flat): dcms[i].show(dicom_windows.brain, ax=ax) show_image(dcms[i].mask_from_blur(dicom_windows.brain), cmap=plt.cm.Reds, alpha=0.6, ax=ax) . def pad_square(x): r,c = x.shape d = (c-r)/2 pl,pr,pt,pb = 0,0,0,0 if d&gt;0: pt,pd = int(math.floor( d)),int(math.ceil( d)) else: pl,pr = int(math.floor(-d)),int(math.ceil(-d)) return np.pad(x, ((pt,pb),(pl,pr)), &#39;minimum&#39;) def crop_mask(x): mask = x.mask_from_blur(dicom_windows.brain) bb = mask2bbox(mask) if bb is None: return lo,hi = bb cropped = x.pixel_array[lo[0]:hi[0],lo[1]:hi[1]] return pad_square(cropped) . _,axs = subplots(1,2) dcm.show(ax=axs[0]) dcm_m = PILCTScan.create(crop_mask(dcm)) dcm_m.show(ax=axs[1]); . Save JPEG images . Now, we will learn to save our smaller images as JPEG for fast prototyping. First, we will sample our dataset to get out freqhist_bins. And then use the samples to calculate our bins. . htypes = &#39;any&#39;,&#39;epidural&#39;,&#39;intraparenchymal&#39;,&#39;intraventricular&#39;,&#39;subarachnoid&#39;,&#39;subdural&#39; def get_samples(df): recs = [df.query(f&#39;{c}==1&#39;).sample() for c in htypes] recs.append(df.query(&#39;any==0&#39;).sample()) return pd.concat(recs).fname.values sample_fns = concat(*dfs.map(get_samples)) sample_dcms = tuple(Path(o).dcmread().scaled_px for o in sample_fns) samples = torch.stack(sample_dcms) bins = samples.freqhist_bins() . sample_fns.shape . (21,) . bins, bins.shape . (tensor([-3024., -2048., -1014., -1007., -1005., -1004., -1003., -1002., -1001., -1000., -999., -998., -997., -995., -994., -993., -991., -990., -988., -985., -981., -977., -973., -970., -967., -964., -960., -956., -951., -945., -936., -924., -909., -891., -866., -835., -801., -758., -691., -574., -351., -126., -70., -41., -15., 4., 11., 17., 21., 23., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 40., 43., 48., 59., 81., 164., 284., 397., 607., 788., 958., 1152., 1390., 1656.]), torch.Size([78])) . with open(f&quot;{path_dest}/bin.pkl&quot;, &quot;wb&quot;) as output_file: pickle.dump(bins, output_file) . Next, we will make a function to read a single dcm file and then fixes them using the fix_pxrepr funtion we create earlier. . def dcm_tfm(fn): fn = Path(fn) try: x = fn.dcmread() fix_pxrepr(x) except Exception as e: print(fn,e) raise SkipItemException if x.Rows != 512 or x.Columns != 512: x.zoom_to((512,512)) return x.scaled_px . We will then make fastai&#39;s TfmDL to use parallel processing to process the images. . comb.fname.values . array([&#39;../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_9ef779a18.dcm&#39;, &#39;../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_ba857d33f.dcm&#39;, &#39;../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_9dcc748d1.dcm&#39;, ..., &#39;../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_8e9f72f61.dcm&#39;, &#39;../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_240b4c94d.dcm&#39;, &#39;../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_515ceb460.dcm&#39;], dtype=object) . fns = list(comb.fname.values) dest = path_dest/&#39;train_jpg&#39; dest.mkdir(exist_ok=True) # NB: Use bs=512 or 1024 when running on GPU bs=4 ds = Datasets(fns, [[dcm_tfm],[os.path.basename]]) dl = TfmdDL(ds, bs=bs, num_workers=2) . As we can see below, the dataloader will return a tuple of scaled_px and its corresponding filename. . dl.one_batch() . (tensor([[[-3024., -3024., -3024., ..., -3024., -3024., -3024.], [-3024., -3024., -3024., ..., -3024., -3024., -3024.], [-3024., -3024., -3024., ..., -3024., -3024., -3024.], ..., [-3024., -3024., -3024., ..., -3024., -3024., -3024.], [-3024., -3024., -3024., ..., -3024., -3024., -3024.], [-3024., -3024., -3024., ..., -3024., -3024., -3024.]], [[-1024., -1024., -1024., ..., -1024., -1024., -1024.], [-1024., -1024., -1024., ..., -1024., -1024., -1024.], [-1005., -1003., -1000., ..., -1004., -1001., -999.], ..., [ -953., -953., -959., ..., -553., -620., -688.], [ -955., -959., -961., ..., -752., -796., -830.], [ -961., -962., -959., ..., -872., -890., -903.]], [[-2048., -2048., -2048., ..., -2048., -2048., -2048.], [-2048., -2048., -2048., ..., -2048., -2048., -2048.], [-2048., -2048., -2048., ..., -2048., -2048., -2048.], ..., [-2048., -2048., -2048., ..., -2048., -2048., -2048.], [-2048., -2048., -2048., ..., -2048., -2048., -2048.], [-2048., -2048., -2048., ..., -2048., -2048., -2048.]], [[ -881., -877., -877., ..., -890., -890., -890.], [ -885., -881., -878., ..., -891., -890., -887.], [ -885., -885., -883., ..., -890., -887., -883.], ..., [ -868., -872., -870., ..., -877., -875., -865.], [ -869., -872., -868., ..., -875., -879., -871.], [ -872., -871., -866., ..., -871., -879., -879.]]]), (&#39;ID_9ef779a18.dcm&#39;, &#39;ID_ba857d33f.dcm&#39;, &#39;ID_9dcc748d1.dcm&#39;, &#39;ID_9b225ec8a.dcm&#39;)) . The following functions return output filename and save the cropped .jpg files. . def dest_fname(fname): return dest/Path(fname).with_suffix(&#39;.jpg&#39;) def save_cropped_jpg(o, dest): fname,px = o px.save_jpg(dest_fname(fname), [dicom_windows.brain, dicom_windows.subdural], bins=bins) . In the next function, we make the following . move the pixels from dataloader to device | make our masks for cropping only the brain portion | then make the crop | use parallel funtioality to save the images. The save_jpg will save brain window, subdural wondow and normalised. Each as one chanel. | def process_batch(pxs, fnames, n_workers=4): pxs = to_device(pxs) masks = pxs.mask_from_blur(dicom_windows.brain) bbs = mask2bbox(masks) gs = crop_resize(pxs, bbs, 256).cpu().squeeze() parallel(save_cropped_jpg, zip(fnames, gs), n_workers=n_workers, progress=False, dest=dest) . %time process_batch(*dl.one_batch(), n_workers=3) . CPU times: user 63.6 ms, sys: 130 ms, total: 194 ms Wall time: 373 ms . Let&#39;s open and see one of the images. . fn = dest.ls()[0] im = Image.open(fn) fn . Path(&#39;train_jpg/ID_ba857d33f.jpg&#39;) . As can be seen below, each channel in the saved jpg corresponds to brain window, subdural window and normalized. . axs = subplots(1, 3)[1].flat for i, ax in zip(tensor(im).permute(2,0,1), axs): ax.imshow(i) ax.axis(&#39;off&#39;) . The above can be simply shown using fastai functionality. . show_images(tensor(im).permute(2,0,1), titles=[&#39;brain&#39;,&#39;subdural&#39;,&#39;normalized&#39;]) . #dest.mkdir(exist_ok=True) #for b in progress_bar(dl): process_batch(*b, n_workers=8) . Building a classifier . For this part, we will be following some part of Jeremy&#39;s 5th notebook. For the full version, please refer to Jeremy&#39;s notebook. . df_comb = comb.set_index(&#39;SOPInstanceUID&#39;) df_tst = pd.read_feather(path_df/&#39;df_tst.fth&#39;) . The next two functions are what we looked in the previous section. We will use the fix_pxrepr function to fix the PixelRepresentation issue we encountered. And make a 3-channel image using brain window, subdural window and normalised image using the freq_his bins we developed earlier. . def fix_pxrepr(dcm): if dcm.PixelRepresentation != 0 or dcm.RescaleIntercept&lt;-100: return x = dcm.pixel_array + 1000 px_mode = 4096 x[x&gt;=px_mode] = x[x&gt;=px_mode] - px_mode dcm.PixelData = x.tobytes() dcm.RescaleIntercept = -1000 . def dcm_tfm(fn): fn = (path_trn/fn).with_suffix(&#39;.dcm&#39;) try: x = fn.dcmread() fix_pxrepr(x) except Exception as e: print(fn,e) raise SkipItemException if x.Rows != 512 or x.Columns != 512: x.zoom_to((512,512)) px = x.scaled_px return TensorImage(px.to_3chan(dicom_windows.brain,dicom_windows.subdural, bins=bins)) . Let&#39;s make a split based on PatientID . set_seed(42) patients = df_comb.PatientID.unique() pat_mask = np.random.random(len(patients))&lt;0.8 pat_trn = patients[pat_mask] . def split_data(df): idx = L.range(df) mask = df.PatientID.isin(pat_trn) return idx[mask],idx[~mask] splits = split_data(df_comb) . filename function returns the filename while fn2image opens the filename and returns PILDicom object . def filename(o): return os.path.splitext(os.path.basename(o))[0] fns = L(list(df_comb.fname)).map(filename) fn = fns[0] fn . &#39;ID_9ef779a18&#39; . def fn2image(fn): return PILDicom.create((path_trn/fn).with_suffix(&#39;.dcm&#39;)) fn2image(fn).show(); . fnlabel return the labels given a filename . htypes = [&#39;any&#39;,&#39;epidural&#39;,&#39;intraparenchymal&#39;,&#39;intraventricular&#39;,&#39;subarachnoid&#39;,&#39;subdural&#39;] def fn2label(fn): return df_comb.loc[fn][htypes].values.astype(np.float32) fn2label(fn) . array([1., 0., 1., 0., 1., 1.], dtype=float32) . get_loss prepares the weighted loss fuction . def get_loss(scale=1.0): loss_weights = tensor(2.0, 1, 1, 1, 1, 1).cuda()*scale return BaseLoss(nn.BCEWithLogitsLoss, pos_weight=loss_weights, floatify=True, flatten=False, is_2d=False) . accuracy_any calculates the accuracy for any label . def accuracy_any(inp, targ, thresh=0.5, sigmoid=True): inp,targ = flatten_check(inp[:,0],targ[:,0]) if sigmoid: inp = inp.sigmoid() return ((inp&gt;thresh)==targ.bool()).float().mean() . loss_func = get_loss(0.14*2) opt_func = partial(Adam, wd=0.01, eps=1e-3) metrics=[accuracy_multi,accuracy_any] . Next, we will need to prepare the dataloaders. . First, we will need the transformations necessary to open/prepare (we will us dcm_tfm) the images and prepare the labels (we will use fn2label followed by EncodedMultiCategorize which makes one-hot encoded multi-category labels). . tfms = [[dcm_tfm], [fn2label, EncodedMultiCategorize(htypes)]] dls = Datasets(fns, tfms, splits=splits) nrm = Normalize(tensor([0.6]),tensor([0.25])) aug = aug_transforms(p_lighting=0.) batch_tfms = [nrm, *aug] . def get_data(bs, sz): return dls.dataloaders(bs=bs, num_workers=nw, after_item=[ToTensor], after_batch=batch_tfms+[AffineCoordTfm(size=sz)]) . dbch = get_data(64,256) x,y = dbch.one_batch() dbch.show_batch(max_n=4) x.shape . (64, 3, 256, 256) . bs = 32 sz=128 . def get_learner(bs, sz): dls = get_data(bs,sz) learn = cnn_learner(dls, xresnet50, loss_func=loss_func, opt_func=opt_func, metrics=metrics) return learn.to_fp16() . learn = get_learner(bs, sz) . learn.fit_one_cycle(1, 1e-3) . . 0.00% [0/1 00:00&lt;00:00] epoch train_loss valid_loss accuracy_multi accuracy_any time . . 89.97% [3649/4056 42:00&lt;04:41 0.1933] &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; This concludes the amazing series of notebooks by Jeremy! . References . https://www.kaggle.com/jhoward/creating-a-metadata-dataframe-fastai . https://www.kaggle.com/jhoward/some-dicom-gotchas-to-be-aware-of-fastai . https://www.kaggle.com/jhoward/don-t-see-like-a-radiologist-fastai . https://blog.kitware.com/dicom-rescale-intercept-rescale-slope-and-itk/#:~:text=What%20is%20Rescale%20Intercept%20%2F%20Rescale,to%20their%20in%20memory%20representation. . &lt;/div&gt; .",
            "url": "https://moarshy.github.io/blogs/dicom/medical%20images/fastai/2021/03/06/dicomcontinued.html",
            "relUrl": "/dicom/medical%20images/fastai/2021/03/06/dicomcontinued.html",
            "date": " • Mar 6, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "What is DICOM?",
            "content": ". Note: Most of the codes used in this blog are either taken from fastbook or fastai docs . What is DICOM? . DICOM stands for Digital Imaging and COmmunication in Medicine | It is a software integration standard that is used in medical imaging | It is the standard that establishes rules that allows different medical imaging modalities (such as X-Rays, Ultrasound, CT, MRI) from different vendors and hospitals to exchange information between them | . There core of DICOM . DICOM File Format | This is the important for part for DL. | DICOM images uses the .dcm extension | .dcm allows patient data, image pixel values to be stored under different tags | Like mentioned above apart from images, DICOM also contains patient details (such as patient name and age) and image acqusition data (such as type of equipment used) | . DICOM Network protocol | The protocol allows for information exchange between different imaging modalities that is connected to the hospital network | Used for searching for images from the archive and to display images on the workstation | This protocol can also be used to monitor treatment, schedule procedures, report status | . Let&#39;s use fastai to read a dcm file and use it to understand the information it contains. We will use the SIIM-ACR Pneumothorax Segentation dataset. . ! pip install fastai -q --upgrade ! pip install pydicom kornia opencv-python scikit-image nbdev -q . |████████████████████████████████| 194kB 18.8MB/s |████████████████████████████████| 61kB 10.7MB/s |████████████████████████████████| 1.9MB 18.6MB/s |████████████████████████████████| 225kB 46.4MB/s |████████████████████████████████| 51kB 8.3MB/s . import fastai print(fastai.__version__) . 2.2.5 . from fastai.basics import * from fastai.callback.all import * from fastai.vision.all import * from fastai.medical.imaging import * import pydicom import pandas as pd . # downloading the dataset pneumothorax_source = untar_data(URLs.SIIM_SMALL) . # reading the dcm files items = get_dicom_files(pneumothorax_source/f&quot;train/&quot;) . # lets read the dcm file for patient 11 patient = 11 xray_sample = items[patient].dcmread() . # lets take a look at the DICOM metafile xray_sample . Dataset.file_meta - (0002, 0000) File Meta Information Group Length UL: 202 (0002, 0001) File Meta Information Version OB: b&#39; x00 x01&#39; (0002, 0002) Media Storage SOP Class UID UI: Secondary Capture Image Storage (0002, 0003) Media Storage SOP Instance UID UI: 1.2.276.0.7230010.3.1.4.8323329.10731.1517875225.339875 (0002, 0010) Transfer Syntax UID UI: JPEG Baseline (Process 1) (0002, 0012) Implementation Class UID UI: 1.2.276.0.7230010.3.0.3.6.0 (0002, 0013) Implementation Version Name SH: &#39;OFFIS_DCMTK_360&#39; - (0008, 0005) Specific Character Set CS: &#39;ISO_IR 100&#39; (0008, 0016) SOP Class UID UI: Secondary Capture Image Storage (0008, 0018) SOP Instance UID UI: 1.2.276.0.7230010.3.1.4.8323329.10731.1517875225.339875 (0008, 0020) Study Date DA: &#39;19010101&#39; (0008, 0030) Study Time TM: &#39;000000.00&#39; (0008, 0050) Accession Number SH: &#39;&#39; (0008, 0060) Modality CS: &#39;CR&#39; (0008, 0064) Conversion Type CS: &#39;WSD&#39; (0008, 0090) Referring Physician&#39;s Name PN: &#39;&#39; (0008, 103e) Series Description LO: &#39;view: PA&#39; (0010, 0010) Patient&#39;s Name PN: &#39;8d26a8e1-0913-4952-b5c9-3dd09b3c8925&#39; (0010, 0020) Patient ID LO: &#39;8d26a8e1-0913-4952-b5c9-3dd09b3c8925&#39; (0010, 0030) Patient&#39;s Birth Date DA: &#39;&#39; (0010, 0040) Patient&#39;s Sex CS: &#39;F&#39; (0010, 1010) Patient&#39;s Age AS: &#39;67&#39; (0018, 0015) Body Part Examined CS: &#39;CHEST&#39; (0018, 5101) View Position CS: &#39;PA&#39; (0020, 000d) Study Instance UID UI: 1.2.276.0.7230010.3.1.2.8323329.10731.1517875225.339874 (0020, 000e) Series Instance UID UI: 1.2.276.0.7230010.3.1.3.8323329.10731.1517875225.339873 (0020, 0010) Study ID SH: &#39;&#39; (0020, 0011) Series Number IS: &#34;1&#34; (0020, 0013) Instance Number IS: &#34;1&#34; (0020, 0020) Patient Orientation CS: &#39;&#39; (0028, 0002) Samples per Pixel US: 1 (0028, 0004) Photometric Interpretation CS: &#39;MONOCHROME2&#39; (0028, 0010) Rows US: 1024 (0028, 0011) Columns US: 1024 (0028, 0030) Pixel Spacing DS: [0.14300000000000002, 0.14300000000000002] (0028, 0100) Bits Allocated US: 8 (0028, 0101) Bits Stored US: 8 (0028, 0102) High Bit US: 7 (0028, 0103) Pixel Representation US: 0 (0028, 2110) Lossy Image Compression CS: &#39;01&#39; (0028, 2114) Lossy Image Compression Method CS: &#39;ISO_10918_1&#39; (7fe0, 0010) Pixel Data OB: Array of 163378 elements . As can be seen, the dataset file has many rows. Each row contains a data element. . An example of a data element is (0028, 0010) Rows US: 1024 . Let&#39;s break down the data element . (0028, 0010) is the tag. There are two parts - Group (0028) and Element (0010). From our example of patient 11 above, we can see that Group 0010 groups all patient details. . In our data element example, the tag is followed by Rows which describes the data element. Following the tag and its description, the next value is Value Representation (VR) which describes the data type of the data element. In our example, the VR is US which means Unsigned Short. The VR is then followed by Value Length. In our example, there are 1024 rows. . There are 1,000s of data elements in the DICOM. In this, we will focus on the 0028 group which describes different image/pixel related attributes and (7fe0, 0010) which describes and contains the pixel data. . (0028, 0002) Samples per pixel - This indicates if the image is grayscale (1) or RGB (3). In our example, we have a grayscale image. | (0028, 0004) Photometric Interpretation - describes the color space of our image. Some of the possible values are - MONOCHROME, MONOCHROME2, PALETTE COLOR, RGB. In our case it is MONOCHROME2 where low values are dark and high values are bright. It is the opposite in MONOCHROME. PALETTE COLOR contains a color image with a single sample per pixel. RGB describes red, green and blue image planes. For RGB, samples per pixel would be 3. | (0028, 0010) Rows - describes the number of rows in the image. In our example, there are 1024 rows. | (0028, 0011) Columns - describes the number of columns in the image. In our example, there are 1024 columns. | (0028, 0030) Pixel Spacing - describes the distance between centers of two neighbouring pixels. In our example [0.19431099999999998, 0.19431099999999998], the first number is the Row Spacing, the second number is the Column Spacing. | (0028, 0100) Bits Allocated - Number of bits allocated for each pixel sample. | (0028, 0101) Bits Stored - Number of bits stored for each pixel sample. A 8 bits image would have pixel value between 0-255. | (0028, 0102) High Bit - Most significant bit for pixel sample data. Each sample shall have the same high bit. | (0028, 0103) Pixel Representation - can either be unsigned(0) or signed(1). If you are like me and need a refresher on signed vs unsigned integer, here is a link | (0028, 2110) Lossy Image Compression - Specifies whether an Image has undergone lossy compression. 00 image has not been subjected to lossy compression. 01 image has been subjected to lossy compression. lossy compression or irreversible compression is the class of data encoding methods that uses inexact approximations and partial data discarding to represent the content. These techniques are used to reduce data size for storing, handling, and transmitting content. | (0028, 2114) Lossy Image Compression Method - the methods used in Lossy Image compression. ISO_10918_1 : JPEG Lossy Compression, ISO_14495_1 : JPEG-LS Near-lossless Compression, ISO_15444_1 : JPEG 2000 Irreversible Compression : ISO_13818_2 MPEG2 Compression, ISO_14496_10 : MPEG-4 AVC/H.264 Compression, ISO_23008_2 : HEVC/H.265 Lossy Compression. In our example, it is ISO_10918_1 which is JPEG Lossy Compression. | (7fe0, 0010) Pixel Data - an array of pixel data. Data type is OB. Let&#39;s take a look below. | . Apart from the above, let&#39;s also understand the below . (0008,0060) Modality - Type of equipment that originally acquired the data used to create the images in this Series.For all the different values, refer here. Some examples are CT : Computed Tomography, CR: Computed Radiography, DX : Digital Radiography, ES : Endoscopy, IVUS : Intravascular Ultrasound | . Let&#39;s take a look at a sample of PixelData . xray_sample.PixelData[:200] . b&#39; xfe xff x00 xe0 x00 x00 x00 x00 xfe xff x00 xe0&#34;~ x02 x00 xff xd8 xff xdb x00C x00 x03 x02 x02 x02 x02 x02 x03 x02 x02 x02 x03 x03 x03 x03 x04 x06 x04 x04 x04 x04 x04 x08 x06 x06 x05 x06 t x08 n n t x08 t t n x0c x0f x0c n x0b x0e x0b t t r x11 r x0e x0f x10 x10 x11 x10 n x0c x12 x13 x12 x10 x13 x0f x10 x10 x10 xff xc0 x00 x0b x08 x04 x00 x04 x00 x01 x01 x11 x00 xff xc4 x00 x1d x00 x00 x02 x03 x01 x01 x01 x01 x01 x00 x00 x00 x00 x00 x00 x00 x00 x04 x05 x00 x03 x06 x02 x07 x01 x08 t xff xc4 x00J x10 x00 x02 x01 x03 x03 x02 x04 x03 x06 x06 x01 x02 x05 x02 x00 x0f x01 x02 x11 x00 x03! x04 x121 x05A x13&#34;Qa x06q x81 x142 x91 xa1 xb1 xf0 x07#B xc1 xd1 xe1 xf1 x15R x08$3br x16C%4Sc tD x82 x92&#39; . As the raw PixelData are complex. Let&#39;s use .pixel_array to read the data in a more familiar format. . xray_sample.pixel_array . array([[ 0, 0, 0, ..., 233, 248, 153], [ 0, 0, 0, ..., 226, 241, 151], [ 0, 0, 0, ..., 208, 223, 140], ..., [ 1, 1, 1, ..., 2, 2, 0], [ 1, 1, 1, ..., 2, 2, 0], [ 1, 1, 1, ..., 2, 2, 0]], dtype=uint8) . Let&#39;s use .show to show the image . xray_sample.show() . fastai provides the following function to create dataframe from the dicom files. Apart from reading the DICOM file, it also calculate summary statistics of the image pixels (mean/min/max/std) when px_summ is set to True . dicom_dataframe = pd.DataFrame.from_dicoms(items, px_summ=True) dicom_dataframe[:5] . SpecificCharacterSet SOPClassUID SOPInstanceUID StudyDate StudyTime AccessionNumber Modality ConversionType ReferringPhysicianName SeriesDescription PatientName PatientID PatientBirthDate PatientSex PatientAge BodyPartExamined ViewPosition StudyInstanceUID SeriesInstanceUID StudyID SeriesNumber InstanceNumber PatientOrientation SamplesPerPixel PhotometricInterpretation Rows Columns PixelSpacing BitsAllocated BitsStored HighBit PixelRepresentation LossyImageCompression LossyImageCompressionMethod fname MultiPixelSpacing PixelSpacing1 img_min img_max img_mean img_std img_pct_window . 0 ISO_IR 100 | 1.2.840.10008.5.1.4.1.1.7 | 1.2.276.0.7230010.3.1.4.8323329.11405.1517875232.807474 | 19010101 | 000000.00 | | CR | WSD | | view: PA | (8, 1, 5, 5, 1, 5, 9, 8, -, a, b, 5, 1, -, 4, e, 5, 7, -, a, 4, d, e, -, 8, d, 0, b, 0, 3, 9, 9, 3, c, 5, 5) | 81551598-ab51-4e57-a4de-8d0b03993c55 | | F | 66 | CHEST | PA | 1.2.276.0.7230010.3.1.2.8323329.11405.1517875232.807473 | 1.2.276.0.7230010.3.1.3.8323329.11405.1517875232.807472 | | 1 | 1 | | 1 | MONOCHROME2 | 1024 | 1024 | 0.171000 | 8 | 8 | 7 | 0 | 01 | ISO_10918_1 | /root/.fastai/data/siim_small/train/No Pneumothorax/000018.dcm | 1 | 0.171000 | 0 | 252 | 150.097208 | 59.213376 | 0.136433 | . 1 ISO_IR 100 | 1.2.840.10008.5.1.4.1.1.7 | 1.2.276.0.7230010.3.1.4.8323329.2126.1517875171.269922 | 19010101 | 000000.00 | | CR | WSD | | view: AP | (4, 4, 2, 7, 4, 9, d, 8, -, 8, 2, 7, 9, -, 4, 3, e, d, -, a, 2, a, 3, -, 8, 5, 1, 8, 3, 9, 3, e, 0, 0, e, b) | 442749d8-8279-43ed-a2a3-8518393e00eb | | M | 28 | CHEST | AP | 1.2.276.0.7230010.3.1.2.8323329.2126.1517875171.269921 | 1.2.276.0.7230010.3.1.3.8323329.2126.1517875171.269920 | | 1 | 1 | | 1 | MONOCHROME2 | 1024 | 1024 | 0.139000 | 8 | 8 | 7 | 0 | 01 | ISO_10918_1 | /root/.fastai/data/siim_small/train/No Pneumothorax/000071.dcm | 1 | 0.139000 | 0 | 255 | 144.198807 | 54.626554 | 0.071772 | . 2 ISO_IR 100 | 1.2.840.10008.5.1.4.1.1.7 | 1.2.276.0.7230010.3.1.4.8323329.31988.1517875157.881392 | 19010101 | 000000.00 | | CR | WSD | | view: PA | (6, 3, a, 4, 0, 2, a, 4, -, 8, 2, 8, c, -, 4, c, c, 4, -, 9, 7, 6, 0, -, 4, 3, 2, 6, 0, 2, 1, 6, 2, 4, 2, 5) | 63a402a4-828c-4cc4-9760-432602162425 | | M | 65 | CHEST | PA | 1.2.276.0.7230010.3.1.2.8323329.31988.1517875157.881391 | 1.2.276.0.7230010.3.1.3.8323329.31988.1517875157.881390 | | 1 | 1 | | 1 | MONOCHROME2 | 1024 | 1024 | 0.168000 | 8 | 8 | 7 | 0 | 01 | ISO_10918_1 | /root/.fastai/data/siim_small/train/No Pneumothorax/000037.dcm | 1 | 0.168000 | 0 | 255 | 176.959857 | 51.083963 | 0.036505 | . 3 ISO_IR 100 | 1.2.840.10008.5.1.4.1.1.7 | 1.2.276.0.7230010.3.1.4.8323329.32498.1517875160.877894 | 19010101 | 000000.00 | | CR | WSD | | view: AP | (c, f, 2, a, 4, 6, 7, f, -, e, b, 2, 0, -, 4, 5, 1, 6, -, 8, f, 3, 6, -, 3, 6, d, e, 2, d, 4, 5, 4, 5, 4, e) | cf2a467f-eb20-4516-8f36-36de2d45454e | | F | 48 | CHEST | AP | 1.2.276.0.7230010.3.1.2.8323329.32498.1517875160.877893 | 1.2.276.0.7230010.3.1.3.8323329.32498.1517875160.877892 | | 1 | 1 | | 1 | MONOCHROME2 | 1024 | 1024 | 0.168000 | 8 | 8 | 7 | 0 | 01 | ISO_10918_1 | /root/.fastai/data/siim_small/train/No Pneumothorax/000135.dcm | 1 | 0.168000 | 0 | 255 | 107.833434 | 65.194095 | 0.241501 | . 4 ISO_IR 100 | 1.2.840.10008.5.1.4.1.1.7 | 1.2.276.0.7230010.3.1.4.8323329.2633.1517875173.805125 | 19010101 | 000000.00 | | CR | WSD | | view: PA | (9, 4, 3, a, 4, e, 9, 3, -, d, 0, 5, 8, -, 4, 8, 8, 4, -, b, c, 6, 1, -, 7, b, 6, f, b, b, 2, 8, 8, c, 8, 5) | 943a4e93-d058-4884-bc61-7b6fbb288c85 | | F | 40 | CHEST | PA | 1.2.276.0.7230010.3.1.2.8323329.2633.1517875173.805124 | 1.2.276.0.7230010.3.1.3.8323329.2633.1517875173.805123 | | 1 | 1 | | 1 | MONOCHROME2 | 1024 | 1024 | 0.194311 | 8 | 8 | 7 | 0 | 01 | ISO_10918_1 | /root/.fastai/data/siim_small/train/No Pneumothorax/000103.dcm | 1 | 0.194311 | 0 | 255 | 96.317883 | 43.559422 | 0.267043 | . We have 250 samples which wouldn&#39;t be sufficient to build anything of significance. We will use it to understand the DICOM data and to learn how fastai can be used to work with medical images. . len(dicom_dataframe) . 250 . Let&#39;s take a look at the different columns. img_min, img_max, img_mean, img_std, img_pct_window are calculated by from_dicom fastai function. . dicom_dataframe.columns . Index([&#39;SpecificCharacterSet&#39;, &#39;SOPClassUID&#39;, &#39;SOPInstanceUID&#39;, &#39;StudyDate&#39;, &#39;StudyTime&#39;, &#39;AccessionNumber&#39;, &#39;Modality&#39;, &#39;ConversionType&#39;, &#39;ReferringPhysicianName&#39;, &#39;SeriesDescription&#39;, &#39;PatientName&#39;, &#39;PatientID&#39;, &#39;PatientBirthDate&#39;, &#39;PatientSex&#39;, &#39;PatientAge&#39;, &#39;BodyPartExamined&#39;, &#39;ViewPosition&#39;, &#39;StudyInstanceUID&#39;, &#39;SeriesInstanceUID&#39;, &#39;StudyID&#39;, &#39;SeriesNumber&#39;, &#39;InstanceNumber&#39;, &#39;PatientOrientation&#39;, &#39;SamplesPerPixel&#39;, &#39;PhotometricInterpretation&#39;, &#39;Rows&#39;, &#39;Columns&#39;, &#39;PixelSpacing&#39;, &#39;BitsAllocated&#39;, &#39;BitsStored&#39;, &#39;HighBit&#39;, &#39;PixelRepresentation&#39;, &#39;LossyImageCompression&#39;, &#39;LossyImageCompressionMethod&#39;, &#39;fname&#39;, &#39;MultiPixelSpacing&#39;, &#39;PixelSpacing1&#39;, &#39;img_min&#39;, &#39;img_max&#39;, &#39;img_mean&#39;, &#39;img_std&#39;, &#39;img_pct_window&#39;], dtype=&#39;object&#39;) . We have CR as the Modelity which is Computed Radiograpy . dicom_dataframe[&#39;Modality&#39;].unique() . array([&#39;CR&#39;], dtype=object) . We can see the age distribution of the patient. . plt.style.use(&#39;seaborn&#39;) dicom_dataframe[&#39;PatientAge&#39;].astype(int).hist(bins=10) plt.xlabel(&#39;Age&#39;) plt.ylabel(&#39;Frequency&#39;) . Text(0, 0.5, &#39;Frequency&#39;) . We have an equal number of M and F . dicom_dataframe[&#39;PatientSex&#39;].hist() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fa9c9cebe10&gt; . Building a classifier with fastai . Next, let&#39;s use fastai.medical to build a simple classifier. Again, we only have 250 samples which won&#39;t be enough to build anything of significance. The goal is to show how we can use fastai.medical to work with medical images. . Let&#39;s get the different folders/files. . pneumothorax_source.ls() . (#2) [Path(&#39;/root/.fastai/data/siim_small/train&#39;),Path(&#39;/root/.fastai/data/siim_small/labels.csv&#39;)] . Let&#39;s read the labels.csv and see what is in it . train = pd.read_csv(pneumothorax_source/&#39;labels.csv&#39;) . Let&#39;s build a simple dataloader . pneumothorax = DataBlock(blocks=(ImageBlock(cls=PILDicom), CategoryBlock), get_x=lambda x:pneumothorax_source/f&quot;{x[0]}&quot;, get_y=lambda x:x[1], splitter=RandomSplitter(), batch_tfms=aug_transforms(size=400)) dls = pneumothorax.dataloaders(train.values, bs=8) . Once, we have made the dataloader, we can take a look at a batch. . dls.show_batch(max_n=8) . Let&#39;s use fastai&#39;s xrestnet model - xresnet is based on &quot;Bag of Tricks for ResNet&quot; paper. We also use Mish activation instead of the usual ReLU and we will use self-attention. . model = xresnet50(pretrained=False, act_cls=Mish, sa=True, n_out=2) . model[0][0] . Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) . # Here, we will set the first layer to accept single channel image model[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) . For the optimizer, we will use ranger which uses RAdam and Lookahead. . learn = Learner(dls, model=model, loss_func=LabelSmoothingCrossEntropy(), metrics= accuracy, opt_func=ranger) . learn.lr_find() . SuggestedLRs(lr_min=3.311311302240938e-05, lr_steep=0.0012022644514217973) . learn.fit_flat_cos(5, 5e-4) . epoch train_loss valid_loss accuracy time . 0 | 0.635151 | 0.681318 | 0.680000 | 00:13 | . 1 | 0.629701 | 0.652602 | 0.680000 | 00:12 | . 2 | 0.614139 | 0.611938 | 0.720000 | 00:13 | . 3 | 0.601922 | 0.743685 | 0.640000 | 00:12 | . 4 | 0.596375 | 0.660376 | 0.700000 | 00:12 | . Interpreting the classifier with fastai . Among the many cool things fastai provides, interpretation is one. Let&#39;s take a look at the classifier and see how well our classifier is doing. . learn.show_results(max_n=8) . # Let&#39;s initiate a ClassificationInterpretation interp = ClassificationInterpretation.from_learner(learn) . Let&#39;s take a look at our top_losses. Our classifier confuses No Pneumothorax for Pneumothorax. This is likely because of the lack of training data. Again, the goal here is to understand how we can use fastai and its many tools. . interp.plot_top_losses(6, figsize=(14,8)) . As expected, there is a lot of False Negative (predicts &quot;No Pneumothorax&quot; when it is &quot;Pneumothorax&quot;) . interp.plot_confusion_matrix(figsize=(7,7)) . CAM and GradCAM . CAM - Class Activation Map . . credits: https://docs.paperspace.com/machine-learning/wiki/interpretability . Interpretability or explainability is the degree to which a model&#39;s prediction/decision can be explained in human terms. This is a huge area of research as often ML models are said to be a black-box with no interpretability. There are certain tools being developed to address this area. Among those tools are CAM and GradCAM. . Class Activation Map (CAM) uses the activation of the last convolution layer and the predictions of the last layer to plot heatmap visualization. The visualization gives an idea of why the model made its decision. In medical imaging, this sort of heatmap visualization could augment radiologists and other doctors apart from doing the classification. Fastbook has a chapter dedicated to CAM and GradCAM which can be found here. . Let&#39;s see how we can make use of CAM. . Below, we define a hook class. Hooks are similar to callbacks and they let us inject codes into forward and backward calculation. . class Hook(): def hook_func(self, m, i, o): self.stored = o.detach().clone() . Let&#39;s define the path for no_pneumothorax and pneumothorax class . nopneumo = (pneumothorax_source/&#39;train&#39;).ls()[0].ls() pneumo = (pneumothorax_source/&#39;train&#39;).ls()[1].ls() . Then, we initiate the Hook class and use the register_forward_hook to attach the hook class to the forward function. learn.model[-5] would access the whole xresnet model without the head and register_forward_hook would be able to attach our hook to the last convolution layer. . hook_output = Hook() hook = learn.model[-5].register_forward_hook(hook_output.hook_func) . Let&#39;s define a function to grab a sampel of image either from nopneumo or pneumo folders. . def grab_x(path, patient): x = first(dls.test_dl([path[patient]])) return x[0] . Let&#39;s define a function to get the CAM map. As you can see we make use of the einsum function. It is awesome funtion and here is one of my fav video on this topic. . def get_cammap(x): with torch.no_grad(): output = learn.model.eval()(x) act = hook_output.stored[0] print(F.softmax(output, dim=-1)) cam_map = torch.einsum(&#39;ck,kij-&gt;cij&#39;, learn.model[-1].weight, act) hook.remove() return cam_map . Then, Let&#39;s define a function to plot two images - left_image = input image and right_image = input image superimposed by the CAM activation heatmap. idx=0 to see nopneumo class activation and idx=1 to see pneumo class activation. . def plot_cam(x, cls, cam_map, img_size=400): x_dec = TensorDicom(dls.train.decode((x,))[0][0]) _,ax = plt.subplots(1,2, figsize=(15,10)) x_dec.show(ctx=ax[0]) x_dec.show(ctx=ax[1]) ax[1].imshow(cam_map[cls].detach().cpu(), alpha=0.6, extent=(0,img_size,img_size,0), interpolation=&#39;bilinear&#39;, cmap=&#39;magma&#39;); . Let&#39;s write a function to wrap everything. . def get_plot_cam_image(path, patient, cls): x = grab_x(path, patient) cam_map = get_cammap(x) plot_cam(x, cls, cam_map, img_size=400) . Below, is an example for No pneumothorax. Areas in bright yellow/orange corresponds to high activations while areas in purple corresponds to low activations. Unfortunately, our classifier hasn&#39;t learnt much to show this. Hence, lets see pic from fastbook. . . The activation map on the cat allows one to peek into model&#39;s &#39;reasons&#39; for its prediction. In medical imaging, this might highlight tumors and other such abnormalities that the radiologists could further scrutanize. . get_plot_image(nopneumo, 5, 0) . tensor([[0.8117, 0.1883]], device=&#39;cuda:0&#39;) . Below is the same image but observing for class=1 or for Pneumothorax. Some of the bright orange are around the lungs as oppose to above where for No Pneumothorax the lungs appeared purple highlighting no activation around the lungs. . get_plot_image(nopneumo, 5, 1) . tensor([[0.8117, 0.1883]], device=&#39;cuda:0&#39;) . GradCAM . Having seen how to use CAM in fastai. Let&#39;s take a look at GradCAM. . GradCAM is similar to CAM except in GradCAM we make use of the gradient to plot the visualization. Because we use gradient, we are able to plot the visualization for the earlier conv layers too. With CAM, we were only able to observe the visualization for the final conv layer because once we obtained the activation of the conv layer, we need to multiply by the last weight matrix.This method only works for the final conv layer. This variant was introduced in the paper - &quot;Grad-CAM: Why Did You Say That? Visual Explanations from Deep Networks via Gradient-based Localization&quot; in 2016. . # A hook to store the output of a layer class Hook(): def __init__(self, m): self.hook = m.register_forward_hook(self.hook_func) def hook_func(self, m, i, o): self.stored = o.detach().clone() def __enter__(self, *args): return self def __exit__(self, *args): self.hook.remove() # A hook to store the grad of a layer class HookBwd(): def __init__(self, m): self.hook = m.register_backward_hook(self.hook_func) def hook_func(self, m, gi, go): self.stored = go[0].detach().clone() def __enter__(self, *args): return self def __exit__(self, *args): self.hook.remove() . def get_gradcammap(x, cls, model_layer): with HookBwd(model_layer) as hookg: with Hook(model_layer) as hook: output = learn.model.eval()(x.cuda()) act = hook.stored output[0,cls].backward() grad = hookg.stored w = grad[0].mean(dim=[1,2], keepdim=True) cam_map = (w * act[0]).sum(0) return cam_map . def plot_gcam(x, img_size=400): x_dec = TensorDicom(dls.train.decode((x,))[0][0]) _,ax = plt.subplots(1,2, figsize=(15,10)) x_dec.show(ctx=ax[0]) x_dec.show(ctx=ax[1]) ax[1].imshow(cam_map.detach().cpu(), alpha=0.6, extent=(0,img_size,img_size,0), interpolation=&#39;bilinear&#39;, cmap=&#39;magma&#39;); . def get_plot_gcam_image(path, patient, cls, layer=-5): x = grab_x(path, patient) cam_map = get_gradcammap(x, cls, layer) plot_gcam(x) . get_plot_gcam_image(nopneumo, 7, cls=0, layer=learn.model[-5]) . get_plot_gcam_image(nopneumo, 7, cls=1, layer=learn.model[-5]) . get_plot_gcam_image(nopneumo, 7, cls=0, layer=learn.model[-5]) . References . https://docs.fast.ai/tutorial.medical_imaging.html . http://dicomiseasy.blogspot.com/2011/10/introduction-to-dicom-chapter-1.html . http://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_C.7.6.3.html#sect_C.7.6.3.1.4 . https://dicom.innolitics.com/ciods/ct-image/image-plane/00280030#:~:text=All%20pixel%20spacing%20related%20Attributes,adjacent%20rows%2C%20or%20vertical%20spacing. .",
            "url": "https://moarshy.github.io/blogs/fastai/medical/interpretability/2021/02/07/whatisdicom.html",
            "relUrl": "/fastai/medical/interpretability/2021/02/07/whatisdicom.html",
            "date": " • Feb 7, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Image Classification Techniques",
            "content": "This is going to be my first blog. I would like to start by stating the motivation for starting this. The main reason for starting is because people I respect in the deep learning (DL) community have all advocated for blogging as part of the learning process. Hence, I am hoping to articulate my learning and understanding through these blogs. It also means I am open to anyone correcting my understanding as well as to add to my current understanding. My blog is mostly going to be around DL and fastai. This year one of my goals is to be around the fastai community so I could learn from the amazing people and the conversation that takes place there. . In this blog, we will go through methods/techniques that help in image classification tasks. The following are the techniques I have been learning and as much as I can I would reference where I learnt the techniques from so anyone could learn from the source. The examples/codes will be using the fastai library. . Image classification is possibly the first task one would encounter when learning DL. Image classification is a computer vision task where a model classifies an image. For example, a cat or dog classifier classifies whether an image is a cat or a dog. . The types of image classifiction tasks . binary image classification - a task in which the model has to predict between two classes (eg. cat or dog) | multi-class image classification - a classification task in which the model has to predict between n-classes (eg. cat, dog, horse or bear) | multi-label image classification - a classification task in which the model has to predict between n-classes and in each prediction there can be one or more than one predictions. (eg. cat and dog) | Throughout this blog we will make use of the Plant Pathology dataset from Kaggle to understand how the different techniques can be applied. . So first, lets understand our dataset. . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . !pip uninstall fastai -q -y !pip install fastai --upgrade -q . |████████████████████████████████| 194kB 17.2MB/s |████████████████████████████████| 61kB 9.7MB/s . from fastai.vision.all import * from sklearn.model_selection import StratifiedKFold . SEED=101 set_seed(SEED) path = Path(&#39;/content/drive/MyDrive/colab_notebooks/fastai/plant_pathology/data&#39;) train = pd.read_csv(path/&#39;train.csv&#39;) train.head(3) . image_id healthy multiple_diseases rust scab . 0 Train_0 | 0 | 0 | 0 | 1 | . 1 Train_1 | 0 | 1 | 0 | 0 | . 2 Train_2 | 1 | 0 | 0 | 0 | . Let&#39;s look at the data. As can see from the above, our train.csv contains the image_id and the labels. There are four classes - healthy, multiple_diseases, rust and scab . train[&#39;labels&#39;] = train.iloc[:, 1:].idxmax(1) train[&#39;labels&#39;].value_counts(), len(train) . (rust 622 scab 592 healthy 516 multiple_diseases 91 Name: labels, dtype: int64, 1821) . In total, there are 1,821 train images. Except for the multiple_diseases class, all other classes have similar number of training examples. One of the problems with this dataset is the relatively low number of multiple_diseases examples in the dataset. Later, we will see how we can use oversampling to help with this. . Now let&#39;s start with the first technique. . 1. k-fold crossvalidation . Oftentimes, training data is scarce and you might want to use all the given data in training but because in crossvalidation (train-validation split) some percentage of data is kept for validation, and that data becomes unavailable for training our model. This is where k-fold crossvalidation could be useful. How does this work? . Create k folds of validation data | Train k models using different validation set each time | During inference, make prediction on all k models and average the results | This way not only we will be ensembling k models during inference, we would also use all the data in the training process. . Let&#39;s see how this is done. . N_FOLDS = 3 train[&#39;fold&#39;] = -1 strat_kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True) for i, (_, test_index) in enumerate(strat_kfold.split(train.image_id.values, train[&#39;labels&#39;].values)): train.iloc[test_index, -1] = i train[&#39;fold&#39;] = train[&#39;fold&#39;].astype(&#39;int&#39;) . train.head(5) . image_id healthy multiple_diseases rust scab labels fold . 0 Train_0 | 0 | 0 | 0 | 1 | scab | 2 | . 1 Train_1 | 0 | 1 | 0 | 0 | multiple_diseases | 2 | . 2 Train_2 | 1 | 0 | 0 | 0 | healthy | 0 | . 3 Train_3 | 0 | 0 | 1 | 0 | rust | 1 | . 4 Train_4 | 1 | 0 | 0 | 0 | healthy | 2 | . We have 3 folds (or 3 differenct validation sets) . train[&#39;fold&#39;].value_counts() . 2 607 1 607 0 607 Name: fold, dtype: int64 . train.groupby([&#39;fold&#39;, &#39;labels&#39;]).size() . fold labels 0 healthy 172 multiple_diseases 30 rust 207 scab 198 1 healthy 172 multiple_diseases 31 rust 207 scab 197 2 healthy 172 multiple_diseases 30 rust 208 scab 197 dtype: int64 . So we have created three validation sets with each sets having 607 samples. Also because we used stratified k-fold, the different classes in each validation sets are about the same. Now we are ready to proceed with training our k models. . 2. Oversampling and undersampling . As we saw earlier, multiple_diseases class has only 90 samples as compared to others averaging around 500+. This might disadvantage the multiple_diseases class as the model might learn to predict multiple_diseases less often to improve the metrics. . In such scenarios, oversampling can be used. Oversampling is nothing but copy-pasting the same training data of a certain class to increase its numbers. . Let&#39;s see how this is done. . def oversampling(df, fold, col2os=&#39;multiple_diseases&#39;, oversampling=3): train_df_no_val = df[df[&#39;fold&#39;] != {fold}] #training set train_df_just_val = df[df[&#39;fold&#39;] == {fold}] #validation set #we only want oversample the multiple_disease class in the training set train_df_bal = pd.concat( [train_df_no_val[train_df_no_val[&#39;labels&#39;] != col2os], train_df_just_val] + [train_df_no_val[train_df_no_val[&#39;labels&#39;] == col2os]] * oversampling ).sample(frac=1.0, random_state=SEED).reset_index(drop=True) train_df_bal.reset_index(drop=True) return train_df_bal . train_os = oversampling(train, 0) . We have more data in train_os where we have used oversampling of multiple_diseases class . len(train), len(train_os) . (1821, 2003) . train_fold0 = train[train[&#39;fold&#39;] != 0] train_os_fold0 = train_os[train_os[&#39;fold&#39;] != 0] . (print(&#39;train without oversamplig&#39;, &#39; n n&#39;, train_fold0[&#39;labels&#39;].value_counts(), &#39; n n&#39;, &#39;train with oversampling&#39;, &#39; n n&#39;, train_os_fold0[&#39;labels&#39;].value_counts(), sep=&quot;&quot;)) . train without oversamplig rust 415 scab 394 healthy 344 multiple_diseases 61 Name: labels, dtype: int64 train with oversampling rust 415 scab 394 healthy 344 multiple_diseases 183 Name: labels, dtype: int64 . As we can see we have 3x our multiple_diseases class after using oversampling. Samples of other classes stay the same. Oversampling as well as its counterpart undersampling can be useful in balancing the sample size of different classes in the dataset. This allows the model to be trained with less bias towards any of the classes. . 3. Techniques from fastbook Chapter 7 . Fastbook is an amazing resource to learn DL and it is my go to resource. In Chapter 7, advanced techniques for training an image classification model are introduced. Let&#39;s see what these techniques are. . Normalization | Data augmentation including MixUp (CutMix) | Progressive resizing | Test time augmentation | Normalization . We know that having the mean and std of our input data around 0 and 1 helps the model train more efficiently and helps in generalization. Hence, normalization is almost a default technique these days. . Generally, when we train image classification we start by transfer learning. These models would have been generally trained using the ImageNet dataset. Hence, when we normalize our data we use the mean and std of ImageNet dataset to normalize our data. . If we are training from scratch, it&#39;s recommended to calculate the mean and std of the dataset for the 3-channels and use that to normalize the data. Also, during inference, the test data should be normalized using whatever stats that were used to normalize during the training. . Doing this in fastai is very easy. Let&#39;s take a look. . Let&#39;s write a function to make our dataloader . def get_dls(fold, df, img_sz=224): datablock = DataBlock( blocks=(ImageBlock, CategoryBlock()), getters=[ ColReader(&#39;image_id&#39;, pref=path/&#39;images&#39;, suff=&#39;.jpg&#39;), ColReader(&#39;labels&#39;) ], splitter=IndexSplitter(df.loc[df.fold==fold].index), item_tfms=Resize(img_sz), ) return datablock.dataloaders(source=df, bs=32) . dls = get_dls(0, train_os) x, y = dls.one_batch() x.mean(dim=[0,2,3]),x.std(dim=[0,2,3]) . (TensorImage([0.3879, 0.5049, 0.2897], device=&#39;cuda:0&#39;), TensorImage([0.1893, 0.1820, 0.1703], device=&#39;cuda:0&#39;)) . Our mean and std are nowhere near 0 and 1. . Below is how we could calculate the mean and std of our dataset. . Note: This would only use the train dataset. Hence, a more stringent way would be to use all images and calculate the mean and std. . m,s = [0., 0., 0.], [0., 0., 0.] count = 0 for x, y in next(iter(dls)): m += np.array(x.mean(dim=[0,2,3]).cpu()) s += np.array(x.std(dim=[0,2,3]).cpu()) count += 1 . m/count , s/count . (array([0.39644337, 0.51481164, 0.30797708]), array([0.19386025, 0.17980762, 0.17882748])) . Let&#39;s modify our get_dls function slightly in the batch_tfms argument. We have normalize and are using imagenet_stats to normalize the data. Let&#39;s see what is imagenet_stats first and see how this has changed our mean and std. . def get_dls(fold, df, img_sz): datablock = DataBlock( blocks=(ImageBlock, CategoryBlock()), getters=[ ColReader(&#39;image_id&#39;, pref=path/&#39;images&#39;, suff=&#39;.jpg&#39;), ColReader(&#39;labels&#39;) ], splitter=IndexSplitter(df.loc[df.fold==fold].index), item_tfms=Resize(img_sz), batch_tfms=[Normalize.from_stats(*imagenet_stats)] ) return datablock.dataloaders(source=df, bs=32) . As can be seen below, imagenet_stats is a tuple that has the mean and std for the three channels. If you have the stats for your dataset, you could also pass it similarly to normalize the data. . imagenet_stats . ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) . dls = get_dls(0, train_os, 224) x, y = dls.one_batch() x.mean(dim=[0,2,3]),x.std(dim=[0,2,3]) . (TensorImage([-0.3794, 0.2188, -0.4551], device=&#39;cuda:0&#39;), TensorImage([0.9271, 0.8399, 0.8564], device=&#39;cuda:0&#39;)) . The mean and std following normalization is much closer to 0 and 1. . Data augmentation, MixUp and CutMix . Data augmentation is a well known technique to improve image classification. Fastai provides many of these data augmentation tools and they can be easily applied while creating the dataloaders like how we normalized earlier. Data augmentation can be passed as an argument in either item_tfms or batch_tfms while creating our datablock. The difference between the both is that the former make use of CPU while the latter make use of GPU. Hence, batch_tfms is the preferred method to carry out most of the augmentation. . Data augmentation essentially allows us to enlarge our dataset size without getting new data. Data augmentation essentially uses synthetic data manipulation to create new images/training data. . Let&#39;s use this image to see some examples of the many data augmentation that comes with fastai. . img = PILImage(PILImage.create((path/&#39;images&#39;).ls()[SEED]).resize((600,400))) img . FlipItem flips the image at the given probability p . _,axs = subplots(2, 4) for ax in axs.flatten(): show_image(FlipItem(p=0.5)(img, split_idx=0), ctx=ax) . Another technique is dihedral, let&#39;s see what it does . _,axs = subplots(2, 4) for ax in axs.flatten(): show_image(DihedralItem(p=1.)(img, split_idx=0), ctx=ax) . RandomCropping the image at given size . _,axs = subplots(2, 4) for ax in axs.flatten(): show_image(RandomCrop(224)(img, split_idx=0), ctx=ax) . And aug_transforms which is an &quot;Utility func to easily create a list of flip, rotate, zoom, warp, lighting transforms.&quot; . timg = TensorImage(array(img)).permute(2,0,1).float()/255. def _batch_ex(bs): return TensorImage(timg[None].expand(bs, *timg.shape).clone()) . Each image is different although the input image was the same . tfms = aug_transforms(pad_mode=&#39;zeros&#39;, mult=2, min_scale=0.5) y = _batch_ex(9) for t in tfms: y = t(y, split_idx=0) _,axs = plt.subplots(2,3, figsize=(12,10)) for i,ax in enumerate(axs.flatten()): show_image(y[i], ctx=ax) . MixUp . MixUp is a data augmentation technique that was introduced in 2018 in this paper. So what happens during a MixUp? . for a training image image_1, a second image image_2 is randomly selected | new_image is created following this formula where alpha is a constant between 0. and 1.0 that is used to mix the two images | new_image = alpha * image_1 + (1-alpha) * image_2 . similarly, the targets of image_1 and image_2 are blended to create new_target | For example, let&#39;s assume we are training a 4-class model and the &gt;one-hot-encode for image_1 is [0., 0., 1., 0.] and image_2 is [0., 0., &gt;0., 1.]. Also, let&#39;s assume alpha is 0.3. The target for our new_image is &gt;[0., 0., 0.3, 0.7]. . new_target = 0.3 * [0., 0., 1., 0.] + (1-0.3) * [0., 0., 0., 1.] . With this, now, we have completely new image for training. | Let&#39;s use the codes from fastai docs to see how our MixUp images look . mixup = MixUp(1.) with Learner(dls, nn.Linear(3,4), loss_func=CrossEntropyLossFlat(), cbs=mixup) as learn: learn.epoch,learn.training = 0,True learn.dl = dls.train b = dls.one_batch() learn._split(b) learn(&#39;before_batch&#39;) _,axs = plt.subplots(3,3, figsize=(9,9)) dls.show_batch(b=(mixup.x,mixup.y), ctxs=axs.flatten()) . epoch train_loss valid_loss time . 0 | 00:01 | . As can be seen, some of our images above look a bit smeared/odd that is because of mixup. As can be seen, using MixUp with fastai is relatively easy. It is passed as a callback argument when we initiate a Learner. It can also be passed as a cbs in fit_one_cycle. . learn.fit_one_cycle(3, cbs=MixUp(1.0)) . Note: the alpha we passed when we initiate the mixup will be used to generate a distribution the size of batch_size hence the alpha varies from one image to another. Below an example of generating the alpha distribution . torch.distributions.beta.Beta(tensor(1.), tensor(1.)).sample((10,)) . tensor([0.4794, 0.3758, 0.1914, 0.6586, 0.6198, 0.5889, 0.1123, 0.9081, 0.2395, 0.4103]) . CutMix . Although CutMix was not covered in the book, it has been added to the fastai library. CutMix is similar to MixUp but instead of blending images together, CutMix works by cropping a portion of image_2 and placing it in image_1. CutMix has been shown to work better than MixUp. . . Source: CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features . Let&#39;s see some examples of CutMix in action . cutmix = CutMix(1.) with Learner(dls, nn.Linear(3,4), loss_func=CrossEntropyLossFlat(), cbs=cutmix) as learn: learn.epoch,learn.training = 0,True learn.dl = dls.train b = dls.one_batch() learn._split(b) learn(&#39;before_batch&#39;) _,axs = plt.subplots(3,3, figsize=(9,9)) dls.show_batch(b=(cutmix.x,cutmix.y), ctxs=axs.flatten()) . epoch train_loss valid_loss time . 0 | 00:01 | . Progressive resizing . As stated in the book, progressive resizing gradually uses larger and larger images as we continue our training. This technique is akin to transfer learning. Our model learns on smaller images and as we increase the image size it carries forward what it had learnt in previous training as well as picks up something additional from the larger images. . Test time augmentation . As taken from the fastbook, &quot;test time augmentation (TTA): During inference or validation, creating multiple versions of each image, using data augmentation, and then taking the average or maximum of the predictions for each augmented version of the image.&quot; . Other things . Different architectures . Generally varying sizes of ResNet would be the first model to try and establish a baseline. After which one could explore other architecture such as efficientnet or the recently released Visual Transformer. . Transfer Learning . In most cases, transfer learning works really well hence it could be the first thing to try for most classification tasks. . 4. Techniques I learned from Zach&#39;s walkwithfastai imagewoof lecture . I highly recommend walkwithfastai course. It is also my go to resource for fastai. In this particular notebook, Zach introduces different techniques that seem to work really well for image classification tasks. Please check the notebook for references and details. Zach also has a lecture using this notebook here. . The notebook introduces the following techniques. . xresnet which is an arch based on the &quot;Bag of Tricks for ResNet&quot; paper | Mish - a new activation function | ranger - a new optimizer that combines RAdam and Lookahead | Self-attention | MaxBlurPool | a different LR scheduler - that uses flatten+anneal scheduling | Label Smoothing Cross Entropy | 5. Softlabeling and progressive label correction . Softlabeling . I came across softlabeling through Isaac Flath&#39;s amazing blog. I think the blog is the best place to get started on softlabeling. . In supervised learning, labels, which are created by humans, could be erroneous. This leads to the labels being &#39;noisy&#39;. This was the case in the Plant Pathology competition and the winner used a similar method (softlabeling) in the winning solution. . How do we deal with such noisy labels? One way is to punish the model less for predicting incorrectly a noisy label. The steps are as follows . Create a k-fold crossvalidation | Train k classifier using different k-fold for sufficient epochs using the noisy labels | Use the classifier to predict on the kth validation set and save the prediction | Upon completion of the above step, you will have two labels - one the noisy label that came with the data label_ori and another predicted by the above classifiers label_pred | Finally, train your actual classifier and this time when labels between label_ori and label_pred differs, adjust the labels using a hyperparameter a | For example, let&#39;s assume we are training a 4-class model and the one-hot-encode for label_ori is [0., 0., 1., 0.] and label_pred is [0., 0., 0., 1.]. Also, let&#39;s assume a is 0.5. Our new_label would be [0., 0., 0.5, 0.5]. By doing this, the model would be punished less for predicting the wrong class as this could be due to noisy labels. . a = 0.5 label_ori = [0., 0., 1., 0.] label_pred = [0., 0., 0., 1.] new_label = a * label_ori + (1-a) * label_pred new_label = [0., 0., 0.5, 0.5] . Progressive Label Correction . I came across this technique in thsi wonderful Kaggle Notebook by Kerem Turgutlu. It is a paper implementation of this paper. . Again, this method works in cases where there are noisy labels in the dataset. This is my understanding of how it is implemented. . During model training, we let a model train normally for a warm_up period. In the above implementation, the warm_up period was 20% of the total iterations. | Once training goes over the warm_up iterations, Progressive Label Correction (PLC) kicks-in | In PLC, after an iteration, mislabeled indexes are identified | Then, we calculate the probabilities of the max prediction class (predicted_probas - the class the model predicted) as well as the actual target class (actual_probas - the class the model should have predicted) of the mislabeled indexes | we check if the absolute difference between predicted_probas and the actual_probas is above a theta value (theta is a hyperparameter we set) | if the difference is higher, then for those mislabeled indexes, we change (‘correct’) the label y to be that predicted by the model | we continue step 2 to step 6 while progressively lowering the theta using a scheduler function (linear scheduler was used in the above notebook). | Let&#39;s take a look what the ProgressiveLabelCorrection callback in the notebook does. . dls = get_dls(0, train_os, 128) . learn = cnn_learner(dls, resnet18, pretrained=True) . Lets assume our learner has been trained for warm_up iterations and see how PLC is applied using this one_batch . learn.fit_one_cycle(1) learn.one_batch(5, learn.dls.one_batch()) . . 0.00% [0/1 00:00&lt;00:00] epoch train_loss valid_loss time . 0 | 1.573150 | 1.102266 | 02:34 | . . 28.57% [6/21 01:46&lt;04:27 1.5732] Here after an iteration, we check the predicted class and compare it to the target (y) to get the mislabelled indexes . preds_max = learn.pred.argmax(-1) mislabeled_idxs = preds_max != learn.y #so we have 32 samples in each iteration (which is the batch_size), of which 8 are mislabelled mislabeled_idxs, len(mislabeled_idxs), mislabeled_idxs.float().sum() . (TensorCategory([False, True, False, True, False, True, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, True, True, False, False, False], device=&#39;cuda:0&#39;), 32, TensorCategory(8., device=&#39;cuda:0&#39;)) . Then we index into the mislabelled items and calclulate the probabilities. . We also index into the mislabelled targets. . mislabeled_probas = learn.pred[mislabeled_idxs].softmax(-1) mislabeled_targs = learn.y[mislabeled_idxs] . Then we pick the probability of the predicted class . predicted_probas = mislabeled_probas.max(-1).values predicted_probas . tensor([0.7182, 0.6797, 0.6050, 0.6181, 0.4840, 0.4588, 0.5954, 0.7079], device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward0&gt;) . We also store the class of the mislabelled items . predicted_targs = mislabeled_probas.max(-1).indices predicted_targs . tensor([2, 1, 0, 3, 0, 0, 1, 2], device=&#39;cuda:0&#39;) . Here we pick the predicted probability of the actual target class (probability for the target class that the model predicted) . eye = torch.eye(dls.c).to(&#39;cuda&#39;) actual_probas = mislabeled_probas[eye[mislabeled_targs].bool()] actual_probas . tensor([0.1144, 0.2731, 0.2278, 0.2835, 0.3380, 0.2353, 0.3692, 0.1910], device=&#39;cuda:0&#39;, grad_fn=&lt;IndexBackward&gt;) . This is an important step we check if the abs difference between predicted_probas and actual_probas is above a hyperparameter theta . theta = 0.3 msk = torch.abs(predicted_probas - actual_probas) &gt; theta #there are 5 items that meets the condition msk . tensor([ True, True, True, True, False, False, False, True], device=&#39;cuda:0&#39;) . We now gather the new targets that was predicted by the model for the 5 items that meets the condition . new_targs = learn.dls.tfms[1][1].vocab[predicted_targs[msk]] new_targs . (#5) [&#39;rust&#39;,&#39;multiple_diseases&#39;,&#39;healthy&#39;,&#39;scab&#39;,&#39;rust&#39;] . Now that we have the new_targs we will update the labels for these indexes in the training set with new_targs. The theta used is progressively lowered. Hence, as the training progresses we would progressively correct the targets even if the difference between probability of the predicted class and predicted probability of actual target class is small. This means as the training progresses we take the prediction by the model as the actual instead of the label that came with the data. . That&#39;s the end of the blog. Please feel free to contact me at @arshyma (Twitter) or marshath@gmail.com if there is anything. Thank you :) .",
            "url": "https://moarshy.github.io/blogs/image_classification/fastai/2021/01/31/first-blog.html",
            "relUrl": "/image_classification/fastai/2021/01/31/first-blog.html",
            "date": " • Jan 31, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://moarshy.github.io/blogs/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://moarshy.github.io/blogs/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}